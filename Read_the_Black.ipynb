{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/4ge+9Mgw7aj4nluj8PSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaruCodes/Deep_Learning-Defect-prediction-framework-using-CodeBERT-and-GAT/blob/main/Read_the_Black.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97RqM6yQU2LX",
        "outputId": "5b910354-85e8-4692-cb55-9dc9c97d384b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z271z2RQyoj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e177ed-4689-42df-c36c-743944837b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q duckdb polars fastparquet datasets tensorflow==2.19.0 lime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/defectors/line_bug_prediction_splits/random/train.parquet.gzip'\n",
        "\n",
        "df = pd.read_parquet(file_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3r49WBAppod",
        "outputId": "5da23808-f099-4f93-b889-2230be4e80ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   datetime                                    commit  \\\n",
            "0 2016-08-11 14:07:40-01:00  01b498ec5109da22bf1b79d86efaecf45426ad51   \n",
            "0 2020-07-24 17:47:46-01:00  007bc310840d9cd5b37983a0c6ba82bd9e551c26   \n",
            "0 2014-07-16 03:51:12-01:00  0786e84a33155ebc8d8d3502e3a7f3060b86a4ec   \n",
            "0 2019-08-15 11:29:05-01:00  00035672a460b6eb5442d2837bc783f8af28c6f3   \n",
            "0 2021-06-08 09:46:09-01:00  00e7e12a3a412ea386806d5d4eeaed345e912940   \n",
            "\n",
            "                    repo                             filepath  \\\n",
            "0  django-rest-framework            rest_framework\\schemas.py   \n",
            "0                 poetry            poetry\\inspection\\info.py   \n",
            "0                 scrapy     scrapy\\contrib\\pipeline\\files.py   \n",
            "0                 django  django\\db\\models\\fields\\__init__.py   \n",
            "0                  black                 src\\black\\linegen.py   \n",
            "\n",
            "                                             content  \\\n",
            "0  b'from importlib import import_module\\n\\nfrom ...   \n",
            "0  b'import glob\\nimport logging\\nimport os\\nimpo...   \n",
            "0  b'\"\"\"\\nFiles Pipeline\\n\"\"\"\\n\\nimport hashlib\\n...   \n",
            "0  b'import collections.abc\\nimport copy\\nimport ...   \n",
            "0  b'\"\"\"\\nGenerating lines of code.\\n\"\"\"\\nfrom fu...   \n",
            "\n",
            "                                             methods  \\\n",
            "0  [insert_into, add_categories, get_api_endpoint...   \n",
            "0  [_find_dist_info, from_directory, from_sdist, ...   \n",
            "0                                  [file_downloaded]   \n",
            "0                                      [get_choices]   \n",
            "0                                     [visit_STRING]   \n",
            "\n",
            "                                               lines  \n",
            "0  [69, 87, 89, 92, 93, 95, 96, 97, 98, 99, 100, ...  \n",
            "0  [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 2...  \n",
            "0                          [14, 15, 16, 17, 18, 264]  \n",
            "0                               [828, 829, 830, 832]  \n",
            "0                                    [229, 230, 231]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "xroS8PZrzAF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbff927c-132c-43ec-cc59-07834c639f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     repo    cnt\n",
            "0                 ansible  39060\n",
            "1                  sentry  33506\n",
            "2                    core  33292\n",
            "3                     ray  16008\n",
            "4                  pandas  14251\n",
            "5                  django  10273\n",
            "6               lightning  10169\n",
            "7                 airflow   9105\n",
            "8                 cpython   6422\n",
            "9            scikit-learn   4571\n",
            "10                 celery   3043\n",
            "11                  spaCy   2262\n",
            "12                 poetry   2083\n",
            "13             localstack   1648\n",
            "14           transformers   1644\n",
            "15              openpilot   1439\n",
            "16                 yolov5   1048\n",
            "17                  numpy    909\n",
            "18                    jax    665\n",
            "19                 redash    642\n",
            "20                  black    500\n",
            "21                 scrapy    390\n",
            "22  django-rest-framework    376\n",
            "23                 pipenv    113\n",
            "24              freqtrade      1\n"
          ]
        }
      ],
      "source": [
        "# Using DuckDB (memory-friendly for large parquet)\n",
        "import duckdb\n",
        "con = duckdb.connect()\n",
        "\n",
        "q = f\"\"\"\n",
        "SELECT repo, COUNT(*) as cnt\n",
        "FROM read_parquet('{file_path}')\n",
        "GROUP BY repo\n",
        "ORDER BY cnt DESC\n",
        "\"\"\"\n",
        "repo_counts = con.execute(q).df()\n",
        "print(repo_counts.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "black_df = df[df['repo'] == 'black']\n"
      ],
      "metadata": {
        "id": "CwaH96nXRrQ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(black_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bZubvJCRu0T",
        "outputId": "bcdd5f6f-4446-4b23-f683-ec3c06abb885"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = black_df.iloc[1]['content'].decode('utf-8', errors='ignore')\n",
        "print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3E98cyJRwhZ",
        "outputId": "32cd41d6-bce5-4b7d-c069-cb0d3c26f05c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"\n",
            "Simple formatting on strings. Further string formatting code is in trans.py.\n",
            "\"\"\"\n",
            "\n",
            "import regex as re\n",
            "import sys\n",
            "from typing import List, Pattern\n",
            "\n",
            "\n",
            "STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n",
            "\n",
            "\n",
            "def sub_twice(regex: Pattern[str], replacement: str, original: str) -> str:\n",
            "    \"\"\"Replace `regex` with `replacement` twice on `original`.\n",
            "\n",
            "    This is used by string normalization to perform replaces on\n",
            "    overlapping matches.\n",
            "    \"\"\"\n",
            "    return regex.sub(replacement, regex.sub(replacement, original))\n",
            "\n",
            "\n",
            "def has_triple_quotes(string: str) -> bool:\n",
            "    \"\"\"\n",
            "    Returns:\n",
            "        True iff @string starts with three quotation characters.\n",
            "    \"\"\"\n",
            "    raw_string = string.lstrip(STRING_PREFIX_CHARS)\n",
            "    return raw_string[:3] in {'\"\"\"', \"'''\"}\n",
            "\n",
            "\n",
            "def lines_with_leading_tabs_expanded(s: str) -> List[str]:\n",
            "    \"\"\"\n",
            "    Splits string into lines and expands only leading tabs (following the normal\n",
            "    Python rules)\n",
            "    \"\"\"\n",
            "    lines = []\n",
            "    for line in s.splitlines():\n",
            "        # Find the index of the first non-whitespace character after a string of\n",
            "        # whitespace that includes at least one tab\n",
            "        match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n",
            "        if match:\n",
            "            first_non_whitespace_idx = match.start(1)\n",
            "\n",
            "            lines.append(\n",
            "                line[:first_non_whitespace_idx].expandtabs()\n",
            "                + line[first_non_whitespace_idx:]\n",
            "            )\n",
            "        else:\n",
            "            lines.append(line)\n",
            "    return lines\n",
            "\n",
            "\n",
            "def fix_docstring(docstring: str, prefix: str) -> str:\n",
            "    # https://www.python.org/dev/peps/pep-0257/#handling-docstring-indentation\n",
            "    if not docstring:\n",
            "        return \"\"\n",
            "    lines = lines_with_leading_tabs_expanded(docstring)\n",
            "    # Determine minimum indentation (first line doesn't count):\n",
            "    indent = sys.maxsize\n",
            "    for line in lines[1:]:\n",
            "        stripped = line.lstrip()\n",
            "        if stripped:\n",
            "            indent = min(indent, len(line) - len(stripped))\n",
            "    # Remove indentation (first line is special):\n",
            "    trimmed = [lines[0].strip()]\n",
            "    if indent < sys.maxsize:\n",
            "        last_line_idx = len(lines) - 2\n",
            "        for i, line in enumerate(lines[1:]):\n",
            "            stripped_line = line[indent:].rstrip()\n",
            "            if stripped_line or i == last_line_idx:\n",
            "                trimmed.append(prefix + stripped_line)\n",
            "            else:\n",
            "                trimmed.append(\"\")\n",
            "    return \"\\n\".join(trimmed)\n",
            "\n",
            "\n",
            "def get_string_prefix(string: str) -> str:\n",
            "    \"\"\"\n",
            "    Pre-conditions:\n",
            "        * assert_is_leaf_string(@string)\n",
            "\n",
            "    Returns:\n",
            "        @string's prefix (e.g. '', 'r', 'f', or 'rf').\n",
            "    \"\"\"\n",
            "    assert_is_leaf_string(string)\n",
            "\n",
            "    prefix = \"\"\n",
            "    prefix_idx = 0\n",
            "    while string[prefix_idx] in STRING_PREFIX_CHARS:\n",
            "        prefix += string[prefix_idx]\n",
            "        prefix_idx += 1\n",
            "\n",
            "    return prefix\n",
            "\n",
            "\n",
            "def assert_is_leaf_string(string: str) -> None:\n",
            "    \"\"\"\n",
            "    Checks the pre-condition that @string has the format that you would expect\n",
            "    of `leaf.value` where `leaf` is some Leaf such that `leaf.type ==\n",
            "    token.STRING`. A more precise description of the pre-conditions that are\n",
            "    checked are listed below.\n",
            "\n",
            "    Pre-conditions:\n",
            "        * @string starts with either ', \", <prefix>', or <prefix>\" where\n",
            "        `set(<prefix>)` is some subset of `set(STRING_PREFIX_CHARS)`.\n",
            "        * @string ends with a quote character (' or \").\n",
            "\n",
            "    Raises:\n",
            "        AssertionError(...) if the pre-conditions listed above are not\n",
            "        satisfied.\n",
            "    \"\"\"\n",
            "    dquote_idx = string.find('\"')\n",
            "    squote_idx = string.find(\"'\")\n",
            "    if -1 in [dquote_idx, squote_idx]:\n",
            "        quote_idx = max(dquote_idx, squote_idx)\n",
            "    else:\n",
            "        quote_idx = min(squote_idx, dquote_idx)\n",
            "\n",
            "    assert (\n",
            "        0 <= quote_idx < len(string) - 1\n",
            "    ), f\"{string!r} is missing a starting quote character (' or \\\").\"\n",
            "    assert string[-1] in (\n",
            "        \"'\",\n",
            "        '\"',\n",
            "    ), f\"{string!r} is missing an ending quote character (' or \\\").\"\n",
            "    assert set(string[:quote_idx]).issubset(\n",
            "        set(STRING_PREFIX_CHARS)\n",
            "    ), f\"{set(string[:quote_idx])} is NOT a subset of {set(STRING_PREFIX_CHARS)}.\"\n",
            "\n",
            "\n",
            "def normalize_string_prefix(s: str, remove_u_prefix: bool = False) -> str:\n",
            "    \"\"\"Make all string prefixes lowercase.\n",
            "\n",
            "    If remove_u_prefix is given, also removes any u prefix from the string.\n",
            "    \"\"\"\n",
            "    match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n",
            "    assert match is not None, f\"failed to match string {s!r}\"\n",
            "    orig_prefix = match.group(1)\n",
            "    new_prefix = orig_prefix.replace(\"F\", \"f\").replace(\"B\", \"b\").replace(\"U\", \"u\")\n",
            "    if remove_u_prefix:\n",
            "        new_prefix = new_prefix.replace(\"u\", \"\")\n",
            "    return f\"{new_prefix}{match.group(2)}\"\n",
            "\n",
            "\n",
            "def normalize_string_quotes(s: str) -> str:\n",
            "    \"\"\"Prefer double quotes but only if it doesn't cause more escaping.\n",
            "\n",
            "    Adds or removes backslashes as appropriate. Doesn't parse and fix\n",
            "    strings nested in f-strings.\n",
            "    \"\"\"\n",
            "    value = s.lstrip(STRING_PREFIX_CHARS)\n",
            "    if value[:3] == '\"\"\"':\n",
            "        return s\n",
            "\n",
            "    elif value[:3] == \"'''\":\n",
            "        orig_quote = \"'''\"\n",
            "        new_quote = '\"\"\"'\n",
            "    elif value[0] == '\"':\n",
            "        orig_quote = '\"'\n",
            "        new_quote = \"'\"\n",
            "    else:\n",
            "        orig_quote = \"'\"\n",
            "        new_quote = '\"'\n",
            "    first_quote_pos = s.find(orig_quote)\n",
            "    if first_quote_pos == -1:\n",
            "        return s  # There's an internal error\n",
            "\n",
            "    prefix = s[:first_quote_pos]\n",
            "    unescaped_new_quote = re.compile(rf\"(([^\\\\]|^)(\\\\\\\\)*){new_quote}\")\n",
            "    escaped_new_quote = re.compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){new_quote}\")\n",
            "    escaped_orig_quote = re.compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){orig_quote}\")\n",
            "    body = s[first_quote_pos + len(orig_quote) : -len(orig_quote)]\n",
            "    if \"r\" in prefix.casefold():\n",
            "        if unescaped_new_quote.search(body):\n",
            "            # There's at least one unescaped new_quote in this raw string\n",
            "            # so converting is impossible\n",
            "            return s\n",
            "\n",
            "        # Do not introduce or remove backslashes in raw strings\n",
            "        new_body = body\n",
            "    else:\n",
            "        # remove unnecessary escapes\n",
            "        new_body = sub_twice(escaped_new_quote, rf\"\\1\\2{new_quote}\", body)\n",
            "        if body != new_body:\n",
            "            # Consider the string without unnecessary escapes as the original\n",
            "            body = new_body\n",
            "            s = f\"{prefix}{orig_quote}{body}{orig_quote}\"\n",
            "        new_body = sub_twice(escaped_orig_quote, rf\"\\1\\2{orig_quote}\", new_body)\n",
            "        new_body = sub_twice(unescaped_new_quote, rf\"\\1\\\\{new_quote}\", new_body)\n",
            "    if \"f\" in prefix.casefold():\n",
            "        matches = re.findall(\n",
            "            r\"\"\"\n",
            "            (?:[^{]|^)\\{  # start of the string or a non-{ followed by a single {\n",
            "                ([^{].*?)  # contents of the brackets except if begins with {{\n",
            "            \\}(?:[^}]|$)  # A } followed by end of the string or a non-}\n",
            "            \"\"\",\n",
            "            new_body,\n",
            "            re.VERBOSE,\n",
            "        )\n",
            "        for m in matches:\n",
            "            if \"\\\\\" in str(m):\n",
            "                # Do not introduce backslashes in interpolated expressions\n",
            "                return s\n",
            "\n",
            "    if new_quote == '\"\"\"' and new_body[-1:] == '\"':\n",
            "        # edge case:\n",
            "        new_body = new_body[:-1] + '\\\\\"'\n",
            "    orig_escape_count = body.count(\"\\\\\")\n",
            "    new_escape_count = new_body.count(\"\\\\\")\n",
            "    if new_escape_count > orig_escape_count:\n",
            "        return s  # Do not introduce more escaping\n",
            "\n",
            "    if new_escape_count == orig_escape_count and orig_quote == '\"':\n",
            "        return s  # Prefer double quotes\n",
            "\n",
            "    return f\"{prefix}{new_quote}{new_body}{new_quote}\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = content.splitlines()\n",
        "print(\"Total lines:\", len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GcsGbyTTrgl",
        "outputId": "be355db1-4de4-45aa-b98e-d675f7757a31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines: 216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row = black_df.iloc[0]\n",
        "\n",
        "print(\"Methods:\")\n",
        "print(row['methods'])\n",
        "\n",
        "print(\"\\nLines:\")\n",
        "print(row['lines'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSsEW7HhSOnT",
        "outputId": "9035cc13-261a-4265-eaee-9e57e507651c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Methods:\n",
            "['visit_STRING']\n",
            "\n",
            "Lines:\n",
            "[229 230 231]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = black_df.iloc[0]['content'].decode('utf-8', errors='ignore')\n",
        "lines_to_print = black_df.iloc[0]['lines']   # [229, 230, 231]\n",
        "\n",
        "all_lines = content.splitlines()\n",
        "\n",
        "for ln in lines_to_print:\n",
        "    if 1 <= ln <= len(all_lines):\n",
        "        print(f\"{ln:04}: {all_lines[ln - 1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jRdeMw-T2b3",
        "outputId": "aeaaceed-bfb2-44ad-9d26-59e5c63fb4cc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0229:             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n",
            "0230:             prefix = get_string_prefix(docstring)\n",
            "0231:             docstring = docstring[len(prefix) :]  # Remove the prefix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at basic info of the original DataFrame\n",
        "print(df.info())\n",
        "\n",
        "# Look at basic info of the repo_counts DataFrame\n",
        "print(repo_counts.info())\n",
        "\n",
        "# Check descriptive statistics of 'cnt' from repo_counts\n",
        "print(repo_counts['cnt'].describe())\n",
        "\n",
        "# See unique values and distribution of 'cnt' from repo_counts\n",
        "print(repo_counts['cnt'].value_counts().head(20))\n",
        "\n",
        "# The cross-check below is already performed by the DuckDB query that created repo_counts\n",
        "# If you wanted to do this with pandas on the original df, you would need to group and count first\n",
        "# print(df.groupby('repo')['repo'].count().reset_index(name='cnt'))"
      ],
      "metadata": {
        "id": "gU1g4nExwSLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ac90a4-83a4-42dc-fa44-bb9c0df8ca00"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 193420 entries, 0 to 43564\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count   Dtype                                \n",
            "---  ------    --------------   -----                                \n",
            " 0   datetime  193420 non-null  datetime64[us, pytz.FixedOffset(-60)]\n",
            " 1   commit    193420 non-null  object                               \n",
            " 2   repo      193420 non-null  object                               \n",
            " 3   filepath  193420 non-null  object                               \n",
            " 4   content   190904 non-null  object                               \n",
            " 5   methods   193420 non-null  object                               \n",
            " 6   lines     193420 non-null  object                               \n",
            "dtypes: datetime64[us, pytz.FixedOffset(-60)](1), object(6)\n",
            "memory usage: 11.8+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 0 to 24\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   repo    25 non-null     object\n",
            " 1   cnt     25 non-null     int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 532.0+ bytes\n",
            "None\n",
            "count       25.000000\n",
            "mean      7736.800000\n",
            "std      11370.847799\n",
            "min          1.000000\n",
            "25%        665.000000\n",
            "50%       2083.000000\n",
            "75%      10169.000000\n",
            "max      39060.000000\n",
            "Name: cnt, dtype: float64\n",
            "cnt\n",
            "39060    1\n",
            "33506    1\n",
            "33292    1\n",
            "16008    1\n",
            "14251    1\n",
            "10273    1\n",
            "10169    1\n",
            "9105     1\n",
            "6422     1\n",
            "4571     1\n",
            "3043     1\n",
            "2262     1\n",
            "2083     1\n",
            "1648     1\n",
            "1644     1\n",
            "1439     1\n",
            "1048     1\n",
            "909      1\n",
            "665      1\n",
            "642      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your full dataset\n",
        "# Filter only rows where repo == \"black\"\n",
        "black_df = df[df['repo'] == 'black']\n",
        "\n",
        "# Inspect the shape (number of rows and columns)\n",
        "print(\"Rows:\", black_df.shape[0], \"Columns:\", black_df.shape[1])\n",
        "\n",
        "# Show first few rows\n",
        "print(black_df.head())\n",
        "\n",
        "# If you want to see all unique commits for black\n",
        "print(\"Unique commits:\", black_df['commit'].nunique())\n",
        "\n",
        "# If you want to see all filepaths involved\n",
        "print(\"Unique filepaths:\", black_df['filepath'].nunique())"
      ],
      "metadata": {
        "id": "vct-RgH3xIYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c7f5c3-7caa-467f-f94e-a4d10d55e0de"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 500 Columns: 7\n",
            "                   datetime                                    commit   repo  \\\n",
            "0 2021-06-08 09:46:09-01:00  00e7e12a3a412ea386806d5d4eeaed345e912940  black   \n",
            "1 2021-06-08 09:46:09-01:00  00e7e12a3a412ea386806d5d4eeaed345e912940  black   \n",
            "2 2021-06-08 09:46:09-01:00  00e7e12a3a412ea386806d5d4eeaed345e912940  black   \n",
            "3 2018-05-28 17:53:54-01:00  023e61a2545b70750d47fe31ac5265ffced16a0c  black   \n",
            "4 2019-03-14 18:09:10-01:00  026c81b83454f176a9f9253cbfb70be2c159d822  black   \n",
            "\n",
            "               filepath                                            content  \\\n",
            "0  src\\black\\linegen.py  b'\"\"\"\\nGenerating lines of code.\\n\"\"\"\\nfrom fu...   \n",
            "1  src\\black\\strings.py  b'\"\"\"\\nSimple formatting on strings. Further s...   \n",
            "2    src\\black\\trans.py  b'\"\"\"\\nString transformers that can split and ...   \n",
            "3              black.py  b'import asyncio\\nimport pickle\\nfrom asyncio....   \n",
            "4              black.py  b'import asyncio\\nfrom asyncio.base_events imp...   \n",
            "\n",
            "                                             methods  \\\n",
            "0                                     [visit_STRING]   \n",
            "1                                [get_string_prefix]   \n",
            "2  [do_transform, _validate_msg, _get_break_idx, ...   \n",
            "3  [write_cache, schedule_formatting, get_cache_f...   \n",
            "4                                                 []   \n",
            "\n",
            "                                               lines  \n",
            "0                                    [229, 230, 231]  \n",
            "1                                               [90]  \n",
            "2                        [414, 434, 544, 1039, 1293]  \n",
            "3  [5, 125, 126, 127, 128, 129, 130, 225, 226, 22...  \n",
            "4                                               [52]  \n",
            "Unique commits: 344\n",
            "Unique filepaths: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many times each filepath appears\n",
        "filepath_counts = black_df['filepath'].value_counts()\n",
        "\n",
        "# Show only filepaths that appear more than once\n",
        "duplicates = filepath_counts[filepath_counts > 1]\n",
        "\n",
        "print(duplicates)\n",
        "\n",
        "# ðŸ‘‰ Count total unique files in this repo\n",
        "num_files = black_df['filepath'].nunique()\n",
        "print(\"Total unique files in black repo:\", num_files)"
      ],
      "metadata": {
        "id": "4jTeSW_a29k7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b606995-3db4-4a2a-87b7-8def5d77a453"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath\n",
            "black.py                             171\n",
            "src\\black\\__init__.py                 72\n",
            "setup.py                              37\n",
            "src\\black\\linegen.py                  18\n",
            "docs\\conf.py                          15\n",
            "blib2to3\\pgen2\\tokenize.py            12\n",
            "src\\black\\mode.py                     12\n",
            "src\\black\\trans.py                    11\n",
            "src\\black\\parsing.py                   9\n",
            "src\\black\\files.py                     9\n",
            "src\\black\\nodes.py                     9\n",
            "src\\black\\comments.py                  8\n",
            "blib2to3\\pgen2\\driver.py               7\n",
            "blib2to3\\pgen2\\grammar.py              6\n",
            "src\\blib2to3\\pgen2\\parse.py            6\n",
            "src\\blib2to3\\pytree.py                 5\n",
            "src\\black_primer\\cli.py                5\n",
            "src\\black\\handle_ipynb_magics.py       5\n",
            "blackd.py                              5\n",
            "src\\black\\lines.py                     5\n",
            "src\\black_primer\\lib.py                5\n",
            "blib2to3\\pygram.py                     4\n",
            "src\\black\\cache.py                     3\n",
            "src\\black\\strings.py                   3\n",
            "src\\black\\output.py                    3\n",
            "blib2to3\\pytree.py                     3\n",
            "src\\blackd\\middlewares.py              3\n",
            "src\\blackd\\__init__.py                 3\n",
            "blib2to3\\pygram.pyi                    3\n",
            "blib2to3\\pgen2\\literals.py             2\n",
            "blib2to3\\pgen2\\driver.pyi              2\n",
            "src\\blib2to3\\pgen2\\tokenize.py         2\n",
            "src\\black\\brackets.py                  2\n",
            "src\\blib2to3\\pgen2\\driver.py           2\n",
            "gallery\\gallery.py                     2\n",
            "scripts\\migrate-black.py               2\n",
            "src\\blib2to3\\pygram.py                 2\n",
            "fuzz.py                                2\n",
            "src\\black\\report.py                    2\n",
            "scripts\\diff_shades_gha_helper.py      2\n",
            "scripts\\fuzz.py                        2\n",
            "src\\blib2to3\\pgen2\\grammar.py          2\n",
            "src\\black\\concurrency.py               2\n",
            "Name: count, dtype: int64\n",
            "Total unique files in black repo: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/defectors/line_bug_prediction_splits/random\"\n",
        "TRAIN_PARQUET = os.path.join(DRIVE_FOLDER, \"train.parquet.gzip\")\n",
        "\n",
        "# Load\n",
        "df_train = pd.read_parquet(TRAIN_PARQUET)"
      ],
      "metadata": {
        "id": "yaTNBAU-HqZ7"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/defectors/line_bug_prediction_splits/random\"\n",
        "VAL_PARQUET   = os.path.join(DRIVE_FOLDER, \"val.parquet.gzip\")\n",
        "\n",
        "# Load\n",
        "df_val   = pd.read_parquet(VAL_PARQUET)"
      ],
      "metadata": {
        "id": "ySoJHMtERz9p"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/defectors/line_bug_prediction_splits/random\"\n",
        "TEST_PARQUET  = os.path.join(DRIVE_FOLDER, \"test.parquet.gzip\")\n",
        "\n",
        "# Load\n",
        "df_test  = pd.read_parquet(TEST_PARQUET)"
      ],
      "metadata": {
        "id": "vRZtrKkORzRs"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train:\", df_train.shape, \"Val:\", df_val.shape, \"Test:\", df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIoaksvCR-hw",
        "outputId": "693d59e4-37ef-485f-d007-a853f6e79b00"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (193420, 7) Val: (10000, 7) Test: (10000, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter black reposotiory\n",
        "\n",
        "df_val_black   = df_val[df_val[\"repo\"] == \"black\"]\n",
        "df_test_black  = df_test[df_test[\"repo\"] == \"black\"]\n",
        "df_train_black = df_train[df_train[\"repo\"] == \"black\"]   # âœ… fixed\n"
      ],
      "metadata": {
        "id": "7pNXT8GFQHk5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "print(\"Val - black rows:\", len(df_val_black))\n",
        "print(\"Test - black rows:\", len(df_test_black))\n",
        "print(\"Train - black rows:\", len(df_train_black))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9HQsZk88vso",
        "outputId": "683795ca-a579-44c6-f1c1-260f876aaab6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val - black rows: 29\n",
            "Test - black rows: 27\n",
            "Train - black rows: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\n",
        "    \"Validation\": df_val_black.columns,\n",
        "    \"Test\": df_test_black.columns,\n",
        "    \"Train\": df_train_black.columns\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "WuIEX9jjQZQf",
        "outputId": "9f44ac58-0249-4f87-9444-b548a071e453"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Validation      Test     Train\n",
              "0   datetime  datetime  datetime\n",
              "1     commit    commit    commit\n",
              "2       repo      repo      repo\n",
              "3   filepath  filepath  filepath\n",
              "4    content   content   content\n",
              "5    methods   methods   methods\n",
              "6      lines     lines     lines"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4db0ba26-7f97-4782-a0fb-bec2fb36a13b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Validation</th>\n",
              "      <th>Test</th>\n",
              "      <th>Train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>datetime</td>\n",
              "      <td>datetime</td>\n",
              "      <td>datetime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>commit</td>\n",
              "      <td>commit</td>\n",
              "      <td>commit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>repo</td>\n",
              "      <td>repo</td>\n",
              "      <td>repo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filepath</td>\n",
              "      <td>filepath</td>\n",
              "      <td>filepath</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>content</td>\n",
              "      <td>content</td>\n",
              "      <td>content</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>methods</td>\n",
              "      <td>methods</td>\n",
              "      <td>methods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lines</td>\n",
              "      <td>lines</td>\n",
              "      <td>lines</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db0ba26-7f97-4782-a0fb-bec2fb36a13b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4db0ba26-7f97-4782-a0fb-bec2fb36a13b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4db0ba26-7f97-4782-a0fb-bec2fb36a13b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-483b238c-5292-4a33-a1ae-04d9be978a07\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-483b238c-5292-4a33-a1ae-04d9be978a07')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-483b238c-5292-4a33-a1ae-04d9be978a07 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Validation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"datetime\",\n          \"commit\",\n          \"methods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"datetime\",\n          \"commit\",\n          \"methods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"datetime\",\n          \"commit\",\n          \"methods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the column\n",
        "df_val_black   = df_val_black.rename(columns={'lines': 'induce_bug'})\n",
        "df_test_black  = df_test_black.rename(columns={'lines': 'induce_bug'})\n",
        "df_train_black = df_train_black.rename(columns={'lines': 'induce_bug'})\n"
      ],
      "metadata": {
        "id": "8cdF0nDiWlZ0"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_val_black.columns.tolist())\n",
        "print(df_test_black.columns.tolist())\n",
        "print(df_train_black.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKAXrCgCWp4G",
        "outputId": "d60f6c42-414d-45bd-935a-64f733a3eeff"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['datetime', 'commit', 'repo', 'filepath', 'content', 'methods', 'induce_bug']\n",
            "['datetime', 'commit', 'repo', 'filepath', 'content', 'methods', 'induce_bug']\n",
            "['datetime', 'commit', 'repo', 'filepath', 'content', 'methods', 'induce_bug']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR   = \"/content/drive/MyDrive/black_only\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Save as CSV\n",
        "df_val_black.to_csv(\n",
        "    os.path.join(OUTPUT_DIR, \"val_black.csv\"),\n",
        "    index=False\n",
        ")\n",
        "\n",
        "df_test_black.to_csv(\n",
        "    os.path.join(OUTPUT_DIR, \"test_black.csv\"),\n",
        "    index=False\n",
        ")\n",
        "\n",
        "df_train_black.to_csv(\n",
        "    os.path.join(OUTPUT_DIR, \"train_black.csv\"),\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "AwH2NupZ80ew"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "\n",
        "VAL_PATH  = \"/content/drive/MyDrive/defectors/line_bug_prediction_splits/random/val.parquet.gzip\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/defectors/line_bug_prediction_splits/random/test.parquet.gzip\"\n",
        "\n",
        "def repo_counts(parquet_path, split_name):\n",
        "    q = f\"\"\"\n",
        "    SELECT repo, COUNT(*) AS cnt\n",
        "    FROM read_parquet('{parquet_path}')\n",
        "    GROUP BY repo\n",
        "    ORDER BY cnt DESC\n",
        "    \"\"\"\n",
        "    df = con.execute(q).df()\n",
        "    print(f\"\\nðŸ“Œ Repo counts for {split_name}\")\n",
        "    print(df.head(30))\n",
        "    return df\n",
        "\n",
        "df_val_counts  = repo_counts(VAL_PATH, \"VAL\")\n",
        "df_test_counts = repo_counts(TEST_PATH, \"TEST\")\n"
      ],
      "metadata": {
        "id": "2rdjss1y9hOx",
        "outputId": "3a83bc10-6f00-4ac8-d902-516cc1412138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ Repo counts for VAL\n",
            "                     repo   cnt\n",
            "0                 ansible  2187\n",
            "1                  sentry  2010\n",
            "2                    core  1306\n",
            "3                     ray   888\n",
            "4                  pandas   671\n",
            "5               lightning   492\n",
            "6                  django   491\n",
            "7                 cpython   431\n",
            "8                 airflow   429\n",
            "9            scikit-learn   239\n",
            "10                 celery   230\n",
            "11                  spaCy    96\n",
            "12           transformers    94\n",
            "13             localstack    77\n",
            "14                 poetry    74\n",
            "15              openpilot    70\n",
            "16                  numpy    44\n",
            "17                 yolov5    38\n",
            "18                 redash    37\n",
            "19                  black    29\n",
            "20                    jax    27\n",
            "21                 scrapy    23\n",
            "22  django-rest-framework    13\n",
            "23                 pipenv     4\n",
            "\n",
            "ðŸ“Œ Repo counts for TEST\n",
            "                     repo   cnt\n",
            "0                 ansible  2318\n",
            "1                  sentry  1969\n",
            "2                    core  1350\n",
            "3                     ray   845\n",
            "4                  pandas   660\n",
            "5               lightning   501\n",
            "6                  django   479\n",
            "7                 cpython   423\n",
            "8                 airflow   420\n",
            "9                  celery   206\n",
            "10           scikit-learn   189\n",
            "11           transformers   107\n",
            "12                  spaCy    97\n",
            "13             localstack    79\n",
            "14                 poetry    75\n",
            "15              openpilot    71\n",
            "16                 redash    41\n",
            "17                  numpy    40\n",
            "18                 yolov5    39\n",
            "19                    jax    34\n",
            "20                  black    27\n",
            "21  django-rest-framework    14\n",
            "22                 scrapy    12\n",
            "23                 pipenv     4\n"
          ]
        }
      ]
    }
  ]
}