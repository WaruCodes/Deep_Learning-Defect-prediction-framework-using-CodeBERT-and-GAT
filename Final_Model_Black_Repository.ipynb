{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvHMuTzAzLjocgCUA0VFOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ab4d60c670040adb22b46ee7b41d9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ea2aed5c3c14fdeaeff9641c96ed701",
              "IPY_MODEL_33f8dc76e8eb45398cdcb169208fb77e",
              "IPY_MODEL_b6b250da77e9464db8792ebf718d087a"
            ],
            "layout": "IPY_MODEL_ef7c21b7e6b74116a528da5501256442"
          }
        },
        "5ea2aed5c3c14fdeaeff9641c96ed701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435e8c1442004db9b3b9535e6000016c",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d5d95074104a6d86d95bcaf816222a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "33f8dc76e8eb45398cdcb169208fb77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db9771b6476740fdbb2f9f12b5968064",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51a6a5b78bf34e30b9b6585b064d1444",
            "value": 25
          }
        },
        "b6b250da77e9464db8792ebf718d087a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c98dbca9aec4ee8affa910db3fff7bd",
            "placeholder": "​",
            "style": "IPY_MODEL_a638761678c840feb08995fc86817914",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.72kB/s]"
          }
        },
        "ef7c21b7e6b74116a528da5501256442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435e8c1442004db9b3b9535e6000016c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d5d95074104a6d86d95bcaf816222a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db9771b6476740fdbb2f9f12b5968064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a6a5b78bf34e30b9b6585b064d1444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c98dbca9aec4ee8affa910db3fff7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a638761678c840feb08995fc86817914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59be2f7a75f944f88d200f2f682e803d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5702ce36c85443cab5f0af4cdddc71f2",
              "IPY_MODEL_492b11dbafed47edbe0741c4b88130dc",
              "IPY_MODEL_54c4a7e16f84412db6eacbf4fd3d934f"
            ],
            "layout": "IPY_MODEL_2baff1d0f7a140a496b81da16d4389cf"
          }
        },
        "5702ce36c85443cab5f0af4cdddc71f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465443a30c484d0abfba76541bc24ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_77caab296fb64bad93320ceb0c11c4cc",
            "value": "vocab.json: "
          }
        },
        "492b11dbafed47edbe0741c4b88130dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5df30bb30f4b2297e139f668c75b88",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d558642a84241869f3c9c9cf61fb0be",
            "value": 1
          }
        },
        "54c4a7e16f84412db6eacbf4fd3d934f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629701fb95c148c7a7748f64c38a5895",
            "placeholder": "​",
            "style": "IPY_MODEL_7a6b9240c4404bc5b1347677ae37d9ea",
            "value": " 899k/? [00:00&lt;00:00, 22.5MB/s]"
          }
        },
        "2baff1d0f7a140a496b81da16d4389cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465443a30c484d0abfba76541bc24ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77caab296fb64bad93320ceb0c11c4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf5df30bb30f4b2297e139f668c75b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5d558642a84241869f3c9c9cf61fb0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629701fb95c148c7a7748f64c38a5895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a6b9240c4404bc5b1347677ae37d9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce3554aeecde4d018c5c563c543bf9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_172ed4b4e0454f07a247340f362d7763",
              "IPY_MODEL_3c8ead055c0942b58105bb5cd4e611bc",
              "IPY_MODEL_e540f5af9acb44e4b22be55fa409874e"
            ],
            "layout": "IPY_MODEL_db84176ffda24b979299675209b53e4f"
          }
        },
        "172ed4b4e0454f07a247340f362d7763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d548495a0c6c4405892dc11e642c4878",
            "placeholder": "​",
            "style": "IPY_MODEL_970c8fdade5146859eca3bec29d0cfb8",
            "value": "merges.txt: "
          }
        },
        "3c8ead055c0942b58105bb5cd4e611bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63caa3fe536a4b01995bbbbd45c31a8e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff6ea4cdddf44d6f861751e80e490309",
            "value": 1
          }
        },
        "e540f5af9acb44e4b22be55fa409874e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896e2d88ae614affbb9cf354e7221c68",
            "placeholder": "​",
            "style": "IPY_MODEL_6a59638ddd5f496686f7db82c74afce4",
            "value": " 456k/? [00:00&lt;00:00, 28.3MB/s]"
          }
        },
        "db84176ffda24b979299675209b53e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d548495a0c6c4405892dc11e642c4878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970c8fdade5146859eca3bec29d0cfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63caa3fe536a4b01995bbbbd45c31a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ff6ea4cdddf44d6f861751e80e490309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "896e2d88ae614affbb9cf354e7221c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a59638ddd5f496686f7db82c74afce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73fdc8ef80944ddb689e853dcde11dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d73aa5fde09c468592a5966ebfdf162e",
              "IPY_MODEL_6684cf9d833b4ce0b3b3b8741a4af058",
              "IPY_MODEL_95648b312e004e6c8d3ce7e0d7c10e7c"
            ],
            "layout": "IPY_MODEL_b17ceab7eee447b9868a2c6c1e0ef5c3"
          }
        },
        "d73aa5fde09c468592a5966ebfdf162e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509eded4e1cb4854830889f8ea16b3ef",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b9ba312cc74e5a8ec1f9d93bc4046d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6684cf9d833b4ce0b3b3b8741a4af058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c45a395ba66d4ea2a3f86809f067c7d4",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f77269ed3526465d87632444f62985d0",
            "value": 150
          }
        },
        "95648b312e004e6c8d3ce7e0d7c10e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6758b7bc473a4c59ad0fdd73f83feb97",
            "placeholder": "​",
            "style": "IPY_MODEL_5b3f2ea2790e41928fcd67e00da0291f",
            "value": " 150/150 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "b17ceab7eee447b9868a2c6c1e0ef5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509eded4e1cb4854830889f8ea16b3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b9ba312cc74e5a8ec1f9d93bc4046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c45a395ba66d4ea2a3f86809f067c7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77269ed3526465d87632444f62985d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6758b7bc473a4c59ad0fdd73f83feb97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3f2ea2790e41928fcd67e00da0291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e1580733534139ad817125fc9e6d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d781a0bf129410db9c29478a18435f2",
              "IPY_MODEL_36e92a7bd4f345e1ac44a885cf31ef57",
              "IPY_MODEL_b82d805c808f4fe6bb6fa4ea42a8d06f"
            ],
            "layout": "IPY_MODEL_1d0cca8e89144878819e16fbb1878eef"
          }
        },
        "3d781a0bf129410db9c29478a18435f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1622092768eb4f8b911e8163febe34a0",
            "placeholder": "​",
            "style": "IPY_MODEL_0e2a9cb712b1477e9273bf51bc73724a",
            "value": "config.json: 100%"
          }
        },
        "36e92a7bd4f345e1ac44a885cf31ef57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b34e4567404ff0b116d8c0e5eccd5c",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9b4f6a6f7634491a2eb1bea5b5347a2",
            "value": 498
          }
        },
        "b82d805c808f4fe6bb6fa4ea42a8d06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ad6b3f46f449d3873670cfafac54ef",
            "placeholder": "​",
            "style": "IPY_MODEL_8c4e394cca0a465d83e2aaa5624555e0",
            "value": " 498/498 [00:00&lt;00:00, 58.4kB/s]"
          }
        },
        "1d0cca8e89144878819e16fbb1878eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1622092768eb4f8b911e8163febe34a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2a9cb712b1477e9273bf51bc73724a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12b34e4567404ff0b116d8c0e5eccd5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b4f6a6f7634491a2eb1bea5b5347a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87ad6b3f46f449d3873670cfafac54ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4e394cca0a465d83e2aaa5624555e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2348ea0f29b4b36a78559a037fd51ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d697c3067c4f37b2217bd6bbaa1b19",
              "IPY_MODEL_9fa08c05a2114fffbb906071b253e3e4",
              "IPY_MODEL_2484dab2bfad464d974e2f6c5e7aac34"
            ],
            "layout": "IPY_MODEL_acc67184d01142a3bb3df561e4ced78f"
          }
        },
        "75d697c3067c4f37b2217bd6bbaa1b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7468e149915e4b5197a95d288475980e",
            "placeholder": "​",
            "style": "IPY_MODEL_53e65426f32d4a9aaeef3ca49593bef5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9fa08c05a2114fffbb906071b253e3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b28b17c7b5c4d478a2ec02168ee8c00",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f3fe169dd034393a0af68359bc1db16",
            "value": 498627950
          }
        },
        "2484dab2bfad464d974e2f6c5e7aac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1c51df7e3441d69cbc324b8412aad0",
            "placeholder": "​",
            "style": "IPY_MODEL_33ddd1b4578f4631ab0ec5546f4f4278",
            "value": " 499M/499M [00:03&lt;00:00, 165MB/s]"
          }
        },
        "acc67184d01142a3bb3df561e4ced78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7468e149915e4b5197a95d288475980e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e65426f32d4a9aaeef3ca49593bef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b28b17c7b5c4d478a2ec02168ee8c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3fe169dd034393a0af68359bc1db16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad1c51df7e3441d69cbc324b8412aad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ddd1b4578f4631ab0ec5546f4f4278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaruCodes/Deep_Learning-Defect-prediction-framework-using-CodeBERT-and-GAT/blob/main/Final_Model_Black_Repository.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW4VO3ug37Zg",
        "outputId": "e6823d47-1ec8-4d13-8d01-4e56028ce24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/black_only/train_black.csv\")\n",
        "val_df   = pd.read_csv(\"/content/drive/MyDrive/black_only/val_black.csv\")\n",
        "test_df  = pd.read_csv(\"/content/drive/MyDrive/black_only/test_black.csv\")\n"
      ],
      "metadata": {
        "id": "Jw7S5GRFufWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.to_dict(orient=\"records\")\n",
        "val_data   = val_df.to_dict(orient=\"records\")\n",
        "test_data  = test_df.to_dict(orient=\"records\")\n"
      ],
      "metadata": {
        "id": "lQ7aCEnSu21w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab/Notebook setup\n",
        "!pip -q install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip -q install transformers==4.41.0 torchmetrics==1.4.0 scikit-learn==1.6.0 tree_sitter==0.20.2 tree_sitter_languages transformers torch\n",
        "!pip -q install torch_geometric==2.6.0 torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu118.html\n",
        "!pip -q install tree_sitter==0.20.2\n",
        "\n",
        "import os, sys, json, math, random, numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
        "from torchmetrics.functional import auroc\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmnTitm_5Aez",
        "outputId": "29a4eac1-c5b1-425b-ff29-133b1c8db759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tree_sitter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDevice: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n",
        "Goal: Read your dataset rows, decode  as UTF‑8 (fixed file after commit), preserve exact line boundaries (including whitespace), and build labels from .\n",
        "\n",
        "Line numbering: This notebook assumes  uses 0-based indices. If yours are 1-based, subtract 1 during preprocessing.\n",
        "\n",
        "Commit/diff metadata: Optional functions are included to enrich samples later"
      ],
      "metadata": {
        "id": "G7imRA0sH-mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1. Imports\n",
        "# ================================\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2. YOUR ORIGINAL ADAPTER (UNCHANGED)\n",
        "# ================================\n",
        "def df_row_to_record(row):\n",
        "    raw = row['content']\n",
        "\n",
        "    # Step 1: Decode bytes → string\n",
        "    if isinstance(raw, (bytes, bytearray)):\n",
        "        content = raw.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "        content = str(raw)\n",
        "\n",
        "    # Step 2: FIX escaped newlines (CRITICAL)\n",
        "    if \"\\\\n\" in content:\n",
        "        content = content.encode('utf-8').decode('unicode_escape')\n",
        "\n",
        "    induce_bug = row['induce_bug']\n",
        "    if isinstance(induce_bug, str):\n",
        "        induce_bug = json.loads(induce_bug)\n",
        "\n",
        "    record = {\n",
        "        \"datetime\": row.get('datetime', ''),\n",
        "        \"committer\": row.get('committer', ''),\n",
        "        \"commit\": row.get('commit', ''),\n",
        "        \"repo\": row.get('repo', ''),\n",
        "        \"filepath\": row.get('filepath', ''),\n",
        "        \"content\": content,           # NOW real multi-line code\n",
        "        \"methods\": row.get('methods', []),\n",
        "        \"induce_bug\": induce_bug,\n",
        "        \"file_label\": int(row.get('file_label', 1 if len(induce_bug) > 0 else 0)),\n",
        "    }\n",
        "    return record\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3. LOAD REAL DATASET\n",
        "# ================================\n",
        "# ⟳ CHANGE THIS PATH TO YOUR DATASET\n",
        "DATASET_PATH = \"/content/drive/MyDrive/black_only/train_black.csv\"\n",
        "\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(\"Loaded dataset size:\", len(df))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4. PREPROCESSING (SAFE & MINIMAL)\n",
        "# ================================\n",
        "def preprocess_df(df):\n",
        "    # Drop rows without code content\n",
        "    df = df.dropna(subset=[\"content\"]).reset_index(drop=True)\n",
        "\n",
        "    # Normalize induce_bug column\n",
        "    def parse_induce_bug(x):\n",
        "        if isinstance(x, list):\n",
        "            return x\n",
        "        if isinstance(x, str):\n",
        "            try:\n",
        "                return json.loads(x)\n",
        "            except:\n",
        "                return []\n",
        "        return []\n",
        "\n",
        "    df[\"induce_bug\"] = df[\"induce_bug\"].apply(parse_induce_bug)\n",
        "\n",
        "    # File-level label\n",
        "    if \"file_label\" not in df.columns:\n",
        "        df[\"file_label\"] = df[\"induce_bug\"].apply(\n",
        "            lambda x: 1 if len(x) > 0 else 0\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = preprocess_df(df)\n",
        "print(\"After preprocessing:\", len(df))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5. SELECT TOP-10 FILES WITH MOST BUGGY LINES\n",
        "# ================================\n",
        "df[\"bug_line_count\"] = df[\"induce_bug\"].apply(len)\n",
        "\n",
        "top10_df = (\n",
        "    df[df[\"bug_line_count\"] > 0]\n",
        "    .sort_values(\"bug_line_count\", ascending=False)\n",
        "    .head(10)\n",
        ")\n",
        "\n",
        "print(\"\\nTop-10 buggy files:\")\n",
        "print(top10_df[[\"filepath\", \"bug_line_count\"]])\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6. CONVERT TO MODEL-READY RECORDS\n",
        "# ================================\n",
        "records = [\n",
        "    df_row_to_record(row)\n",
        "    for _, row in top10_df.iterrows()\n",
        "]\n",
        "\n",
        "print(\"\\nConverted records:\", len(records))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7. OPTIONAL: BATCH ITERATOR (FOR TRAINING)\n",
        "# ================================\n",
        "def batch_iterator(df, batch_size=16):\n",
        "    for start in range(0, len(df), batch_size):\n",
        "        batch = df.iloc[start:start + batch_size]\n",
        "        yield [\n",
        "            df_row_to_record(row)\n",
        "            for _, row in batch.iterrows()\n",
        "        ]\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 8. QUICK SANITY CHECK\n",
        "# ================================\n",
        "sample = records[0]\n",
        "\n",
        "print(\"\\n--- SAMPLE RECORD ---\")\n",
        "print(\"File:\", sample[\"filepath\"])\n",
        "print(\"Buggy lines:\", sample[\"induce_bug\"])\n",
        "print(\"Total lines:\", len(sample[\"content\"].splitlines()))\n",
        "print(\"File label:\", sample[\"file_label\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlBrRkkPOG-A",
        "outputId": "b5806d9b-0f81-4662-ee6f-ebe7eb6db255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset size: 500\n",
            "After preprocessing: 499\n",
            "\n",
            "Top-10 buggy files:\n",
            "                   filepath  bug_line_count\n",
            "1      src\\black\\strings.py               1\n",
            "4                  black.py               1\n",
            "6   src\\black_primer\\cli.py               1\n",
            "20                 setup.py               1\n",
            "25    src\\black\\brackets.py               1\n",
            "36  src\\black_primer\\cli.py               1\n",
            "42        src\\black\\mode.py               1\n",
            "70                 setup.py               1\n",
            "74                 setup.py               1\n",
            "76             docs\\conf.py               1\n",
            "\n",
            "Converted records: 10\n",
            "\n",
            "--- SAMPLE RECORD ---\n",
            "File: src\\black\\strings.py\n",
            "Buggy lines: [90]\n",
            "Total lines: 217\n",
            "File label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample[\"content\"].splitlines())  # ✅ correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PzbtZFrHHvr",
        "outputId": "cabfa867-2b1c-4da7-c1f8-05f5277db485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "217"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv(DATASET_PATH)\n",
        "print(df_raw[\"content\"].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpgWo63pIQrY",
        "outputId": "82128191-a28b-40bf-eb23-73f96a706a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = sample[\"content\"].splitlines()\n",
        "induce_bug = sample[\"induce_bug\"]\n",
        "len(lines) > max(induce_bug) if induce_bug else True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiJ7_xUOJhsG",
        "outputId": "3cc6a0b0-fdca-425a-f9f7-5f7e0af2a1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHCJLxS3OhQ3",
        "outputId": "d3b8525e-e0fa-46fe-8072-883c49cdef97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['datetime', 'commit', 'repo', 'filepath', 'content', 'methods', 'induce_bug', 'file_label', 'bug_line_count']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn the preprocessing in to reusable pipeline\n",
        "\n",
        "def load_and_preprocess(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Loaded {csv_path}: {len(df)} rows\")\n",
        "\n",
        "    df = preprocess_df(df)\n",
        "    print(f\"After preprocessing: {len(df)} rows\")\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "ejpwLAaamLeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All splits using same pipeline\n",
        "\n",
        "train_df = load_and_preprocess(\"/content/drive/MyDrive/black_only/train_black.csv\")\n",
        "val_df   = load_and_preprocess(\"/content/drive/MyDrive/black_only/val_black.csv\")\n",
        "test_df  = load_and_preprocess(\"/content/drive/MyDrive/black_only/test_black.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlXclTiZmUeO",
        "outputId": "d38f27f5-922c-4b42-f844-1c7f80deb6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded /content/drive/MyDrive/black_only/train_black.csv: 500 rows\n",
            "After preprocessing: 499 rows\n",
            "Loaded /content/drive/MyDrive/black_only/val_black.csv: 29 rows\n",
            "After preprocessing: 28 rows\n",
            "Loaded /content/drive/MyDrive/black_only/test_black.csv: 27 rows\n",
            "After preprocessing: 27 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert data frames in to records\n",
        "\n",
        "def df_to_records(df):\n",
        "    return [df_row_to_record(row) for _, row in df.iterrows()]\n",
        "\n",
        "train_records = df_to_records(train_df)\n",
        "val_records   = df_to_records(val_df)\n",
        "test_records  = df_to_records(test_df)\n"
      ],
      "metadata": {
        "id": "ZhdZ02_rmb0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bug statics per splits\n",
        "\n",
        "def print_stats(name, records):\n",
        "    buggy = sum(len(r[\"induce_bug\"]) > 0 for r in records)\n",
        "    print(f\"{name}: {len(records)} files | {buggy} buggy\")\n",
        "\n",
        "print_stats(\"Train\", train_records)\n",
        "print_stats(\"Val\", val_records)\n",
        "print_stats(\"Test\", test_records)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSzwq5RVng-B",
        "outputId": "ad7c1ef6-14af-47ee-f6ae-b91e97ab7dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 499 files | 43 buggy\n",
            "Val: 28 files | 2 buggy\n",
            "Test: 27 files | 0 buggy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Commit diff enrichment\n",
        "This step shows how you could fetch commit diffs and highlight changed lines. It’s optional and may require auth for large-scale use."
      ],
      "metadata": {
        "id": "M-yFSGYJ_YWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "\n",
        "def fetch_github_diff(owner, repo, commit_hash):\n",
        "    \"\"\"\n",
        "    Fetch unified diff for a public GitHub repo commit.\n",
        "    Returns raw diff text or None on failure.\n",
        "    \"\"\"\n",
        "    url = f\"https://github.com/{owner}/{repo}/commit/{commit_hash}.diff\"\n",
        "    try:\n",
        "        r = requests.get(url, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            return r.text\n",
        "    except Exception as e:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def parse_changed_lines_from_diff(diff_text, target_filepath):\n",
        "    \"\"\"\n",
        "    Very light parser to extract changed line numbers (post-commit) for a single file.\n",
        "    Parses hunk headers like @@ -a,b +c,d @@ and counts added lines in that hunk.\n",
        "    Returns set of 0-based indices for lines in the post-commit file that were changed.\n",
        "    \"\"\"\n",
        "    if diff_text is None:\n",
        "        return set()\n",
        "    changed = set()\n",
        "    current_file = None\n",
        "    for line in diff_text.splitlines():\n",
        "        if line.startswith(\"diff --git\"):\n",
        "            current_file = None\n",
        "        elif line.startswith(\"+++ b/\"):\n",
        "            current_file = line[len(\"+++ b/\"):].strip()\n",
        "        elif current_file == target_filepath and line.startswith(\"@@\"):\n",
        "            # Example: @@ -10,7 +10,9 @@\n",
        "            m = re.search(r\"\\+(\\d+),?(\\d+)?\", line)\n",
        "            if not m:\n",
        "                continue\n",
        "            start = int(m.group(1))\n",
        "            count = int(m.group(2)) if m.group(2) else 1\n",
        "            # Track indices in the post-commit file; subtract 1 for 0-based\n",
        "            for idx in range(start-1, start-1+count):\n",
        "                changed.add(idx)\n",
        "        # Note: A robust parser should also handle '+' lines inside hunks to mark added lines.\n",
        "    return changed\n",
        "\n",
        "# Example usage (public repo): owner='psf', repo='black', commit='00e7e12a3a412ea386806d5d4eeaed345e912940'\n",
        "# diff = fetch_github_diff('psf', 'black', '00e7e12a3a412ea386806d5d4eeaed345e912940')\n",
        "# changed = parse_changed_lines_from_diff(diff, 'src/black/linegen.py')\n",
        "# print(\"Changed lines (post-commit, 0-based):\", sorted(list(changed))[:20])"
      ],
      "metadata": {
        "id": "e-tLvrO2BTdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: fetch diff and print changed lines\n",
        "\n",
        "owner = \"psf\"\n",
        "repo = \"black\"\n",
        "commit_hash = \"00e7e12a3a412ea386806d5d4eeaed345e912940\"\n",
        "target_filepath = \"src/black/linegen.py\"\n",
        "\n",
        "diff = fetch_github_diff(owner, repo, commit_hash)\n",
        "\n",
        "if diff is None:\n",
        "    print(\"Failed to fetch diff\")\n",
        "else:\n",
        "    changed = parse_changed_lines_from_diff(diff, target_filepath)\n",
        "    print(\"Changed lines (post-commit, 0-based):\")\n",
        "    print(sorted(changed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX2rIkBXCTX4",
        "outputId": "ebc256c5-e1c1-4add-e4fa-936dd99c60d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed lines (post-commit, 0-based):\n",
            "[225, 226, 227, 228, 229, 230, 231, 232, 233]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line tokenization and CodeBERT embeddings\n",
        "Keep whitespace: We never strip or trim lines. We split by  exactly to preserve  alignment.\n",
        "Embedding strategy: Use CodeBERT’s [CLS] embedding per line. Then contextualize with BiLSTM across lines to capture neighbors."
      ],
      "metadata": {
        "id": "FErT7_oUDCOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeBERT\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "codebert = RobertaModel.from_pretrained(\"microsoft/codebert-base\").to(device)\n",
        "codebert.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def embed_lines_with_codebert(lines, max_len=128):\n",
        "    # Returns tensor [L, 768]; preserves line indices and whitespace alignment\n",
        "    embs = []\n",
        "    for line in lines:\n",
        "        tokens = tokenizer.encode(line, truncation=True, max_length=max_len)\n",
        "        input_ids = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        outputs = codebert(input_ids)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]  # [1, 768]\n",
        "        embs.append(cls_emb.squeeze(0))\n",
        "    return torch.stack(embs, dim=0)\n",
        "\n",
        "# BiLSTM contextualizer\n",
        "class ContextEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=768, hidden=256, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(in_dim, hidden, num_layers=num_layers,\n",
        "                            bidirectional=True, batch_first=True, dropout=dropout)\n",
        "        self.proj = nn.Linear(hidden*2, hidden*2)\n",
        "        self.norm = nn.LayerNorm(hidden*2)\n",
        "\n",
        "    def forward(self, x):  # x: [B, L, 768]\n",
        "        h, _ = self.lstm(x)\n",
        "        y = self.norm(torch.tanh(self.proj(h)))  # [B, L, 512]\n",
        "        return y\n",
        "\n",
        "context_encoder = ContextEncoder().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "9ab4d60c670040adb22b46ee7b41d9b8",
            "5ea2aed5c3c14fdeaeff9641c96ed701",
            "33f8dc76e8eb45398cdcb169208fb77e",
            "b6b250da77e9464db8792ebf718d087a",
            "ef7c21b7e6b74116a528da5501256442",
            "435e8c1442004db9b3b9535e6000016c",
            "e6d5d95074104a6d86d95bcaf816222a",
            "db9771b6476740fdbb2f9f12b5968064",
            "51a6a5b78bf34e30b9b6585b064d1444",
            "5c98dbca9aec4ee8affa910db3fff7bd",
            "a638761678c840feb08995fc86817914",
            "59be2f7a75f944f88d200f2f682e803d",
            "5702ce36c85443cab5f0af4cdddc71f2",
            "492b11dbafed47edbe0741c4b88130dc",
            "54c4a7e16f84412db6eacbf4fd3d934f",
            "2baff1d0f7a140a496b81da16d4389cf",
            "465443a30c484d0abfba76541bc24ef7",
            "77caab296fb64bad93320ceb0c11c4cc",
            "bf5df30bb30f4b2297e139f668c75b88",
            "5d558642a84241869f3c9c9cf61fb0be",
            "629701fb95c148c7a7748f64c38a5895",
            "7a6b9240c4404bc5b1347677ae37d9ea",
            "ce3554aeecde4d018c5c563c543bf9b2",
            "172ed4b4e0454f07a247340f362d7763",
            "3c8ead055c0942b58105bb5cd4e611bc",
            "e540f5af9acb44e4b22be55fa409874e",
            "db84176ffda24b979299675209b53e4f",
            "d548495a0c6c4405892dc11e642c4878",
            "970c8fdade5146859eca3bec29d0cfb8",
            "63caa3fe536a4b01995bbbbd45c31a8e",
            "ff6ea4cdddf44d6f861751e80e490309",
            "896e2d88ae614affbb9cf354e7221c68",
            "6a59638ddd5f496686f7db82c74afce4",
            "f73fdc8ef80944ddb689e853dcde11dc",
            "d73aa5fde09c468592a5966ebfdf162e",
            "6684cf9d833b4ce0b3b3b8741a4af058",
            "95648b312e004e6c8d3ce7e0d7c10e7c",
            "b17ceab7eee447b9868a2c6c1e0ef5c3",
            "509eded4e1cb4854830889f8ea16b3ef",
            "b2b9ba312cc74e5a8ec1f9d93bc4046d",
            "c45a395ba66d4ea2a3f86809f067c7d4",
            "f77269ed3526465d87632444f62985d0",
            "6758b7bc473a4c59ad0fdd73f83feb97",
            "5b3f2ea2790e41928fcd67e00da0291f",
            "59e1580733534139ad817125fc9e6d2b",
            "3d781a0bf129410db9c29478a18435f2",
            "36e92a7bd4f345e1ac44a885cf31ef57",
            "b82d805c808f4fe6bb6fa4ea42a8d06f",
            "1d0cca8e89144878819e16fbb1878eef",
            "1622092768eb4f8b911e8163febe34a0",
            "0e2a9cb712b1477e9273bf51bc73724a",
            "12b34e4567404ff0b116d8c0e5eccd5c",
            "e9b4f6a6f7634491a2eb1bea5b5347a2",
            "87ad6b3f46f449d3873670cfafac54ef",
            "8c4e394cca0a465d83e2aaa5624555e0",
            "a2348ea0f29b4b36a78559a037fd51ef",
            "75d697c3067c4f37b2217bd6bbaa1b19",
            "9fa08c05a2114fffbb906071b253e3e4",
            "2484dab2bfad464d974e2f6c5e7aac34",
            "acc67184d01142a3bb3df561e4ced78f",
            "7468e149915e4b5197a95d288475980e",
            "53e65426f32d4a9aaeef3ca49593bef5",
            "1b28b17c7b5c4d478a2ec02168ee8c00",
            "5f3fe169dd034393a0af68359bc1db16",
            "ad1c51df7e3441d69cbc324b8412aad0",
            "33ddd1b4578f4631ab0ec5546f4f4278"
          ]
        },
        "id": "rVxqxmRrDG1R",
        "outputId": "1a026ba1-b347-4d25-b0ce-f0c23bb7ffc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab4d60c670040adb22b46ee7b41d9b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59be2f7a75f944f88d200f2f682e803d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce3554aeecde4d018c5c563c543bf9b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f73fdc8ef80944ddb689e853dcde11dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59e1580733534139ad817125fc9e6d2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2348ea0f29b4b36a78559a037fd51ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph construction: AST + CFG-lite + PDG-lite → CPG\n",
        "AST: Tree-sitter Python grammar to gather node spans. We link consecutive lines inside the same span.\n",
        "\n",
        "CFG-lite: Simple sequential edges line i ↔ i+1. This keeps the graph sparse and Colab-friendly.\n",
        "\n",
        "PDG-lite: Connect lines that share identifier names (excluding Python keywords), within a local window."
      ],
      "metadata": {
        "id": "7DqsU8fSDnRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tree-sitter tree-sitter-languages\n",
        "!pip install torch\n",
        "from tree_sitter import Language, Parser\n",
        "from tree_sitter_languages import get_language\n",
        "import torch\n",
        "\n",
        "\n",
        "# Build Python grammar\n",
        "\n",
        "from tree_sitter import Parser\n",
        "\n",
        "PY_LANGUAGE = get_language(\"python\")\n",
        "\n",
        "parser = Parser()\n",
        "parser.set_language(PY_LANGUAGE)\n",
        "\n",
        "\n",
        "def parse_ast_spans(code):\n",
        "    tree = parser.parse(code.encode(\"utf8\"))\n",
        "    root = tree.root_node\n",
        "    spans = []\n",
        "\n",
        "    def visit(node):\n",
        "        spans.append((node.type, node.start_point[0], node.end_point[0]))  # 0-based lines\n",
        "        for child in node.children:\n",
        "            visit(child)\n",
        "\n",
        "    visit(root)\n",
        "    return spans\n",
        "\n",
        "\n",
        "def extract_identifiers_python(line):\n",
        "    tokens = [t for t in ''.join([c if (c.isalnum() or c=='_') else ' ' for c in line]).split() if len(t) > 1]\n",
        "    stop = set([\n",
        "        \"def\",\"class\",\"return\",\"if\",\"else\",\"elif\",\"for\",\"while\",\"import\",\"from\",\"as\",\"with\",\n",
        "        \"try\",\"except\",\"finally\",\"True\",\"False\",\"None\",\"and\",\"or\",\"not\",\"in\",\"is\",\"lambda\",\n",
        "        \"global\",\"nonlocal\",\"assert\",\"yield\",\"pass\",\"break\",\"continue\",\"raise\"\n",
        "    ])\n",
        "    return [t for t in tokens if t not in stop]\n",
        "\n",
        "def build_cpg(lines, max_window=15):\n",
        "    num_lines = len(lines)\n",
        "    edge_index = []\n",
        "    edge_type = []  # 0=sequential, 1=AST-span adjacency, 2=def-use PDG-lite\n",
        "\n",
        "    # CFG-lite: sequential edges\n",
        "    for i in range(num_lines-1):\n",
        "        edge_index.append([i, i+1]); edge_type.append(0)\n",
        "        edge_index.append([i+1, i]); edge_type.append(0)\n",
        "\n",
        "    # AST-lite: adjacency inside span ranges\n",
        "    code = \"\\n\".join(lines)\n",
        "    spans = parse_ast_spans(code)\n",
        "    for tp, s, e in spans:\n",
        "        s = max(0, min(s, num_lines-1))\n",
        "        e = max(0, min(e, num_lines-1))\n",
        "        for i in range(s, e):\n",
        "            edge_index.append([i, i+1]); edge_type.append(1)\n",
        "            edge_index.append([i+1, i]); edge_type.append(1)\n",
        "\n",
        "    # PDG-lite: co-occurrence window edges for identifiers\n",
        "    id_map = {}\n",
        "    for i, line in enumerate(lines):\n",
        "        ids = extract_identifiers_python(line)\n",
        "        for tok in ids:\n",
        "            id_map.setdefault(tok, []).append(i)\n",
        "    for tok, idxs in id_map.items():\n",
        "        idxs = sorted(set(idxs))\n",
        "        for a in idxs:\n",
        "            for b in idxs:\n",
        "                if a != b and abs(a-b) <= max_window:\n",
        "                    edge_index.append([a, b]); edge_type.append(2)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous() if edge_index else torch.empty((2,0), dtype=torch.long)\n",
        "    edge_type = torch.tensor(edge_type, dtype=torch.long) if edge_type else torch.empty((0,), dtype=torch.long)\n",
        "    return edge_index, edge_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O0dOqSxDvFd",
        "outputId": "4a201b45-15e1-474a-d6f3-e60ab753ac05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tree-sitter in /usr/local/lib/python3.12/dist-packages (0.20.2)\n",
            "Requirement already satisfied: tree-sitter-languages in /usr/local/lib/python3.12/dist-packages (1.10.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset class\n",
        "Function: Turn each record into a graph sample:\n",
        "\n",
        "CodeBERT embeddings → BiLSTM contextualization → node features\n",
        "\n",
        "Build CPG-lite edges\n",
        "\n",
        "Prepare line labels from  (exact indices preserved)\n",
        "\n",
        "File label for the file-level head"
      ],
      "metadata": {
        "id": "dA0r4JKWFePs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset wrapper (unchanged)\n",
        "# -----------------------------\n",
        "class LineGraphSample:\n",
        "    def __init__(self, x, edge_index, edge_type, line_labels, file_label, mask_lines):\n",
        "        self.x = x\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_type = edge_type\n",
        "        self.line_labels = line_labels\n",
        "        self.file_label = file_label\n",
        "        self.mask_lines = mask_lines\n",
        "\n",
        "\n",
        "class DefectDataset(Dataset):\n",
        "    def __init__(self, records, cache=True):\n",
        "        self.records = records\n",
        "        self.cache = cache\n",
        "        self._cache = [None] * len(records)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.cache and self._cache[idx] is not None:\n",
        "            return self._cache[idx]\n",
        "\n",
        "        rec = self.records[idx]\n",
        "        lines = rec[\"content\"].split(\"\\n\")   # keep original line indices\n",
        "        L = len(lines)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            line_embs = embed_lines_with_codebert(lines)   # [L, 768]\n",
        "\n",
        "        ctx_inp = line_embs.unsqueeze(0)                   # [1, L, 768]\n",
        "        ctx_out = context_encoder(ctx_inp).squeeze(0)      # [L, 512]\n",
        "\n",
        "        edge_index, edge_type = build_cpg(lines)\n",
        "\n",
        "        # ----- line-level labels (0-based) -----\n",
        "        line_labels = torch.zeros(L, dtype=torch.float32)\n",
        "        for ln in rec[\"induce_bug\"]:\n",
        "            if 0 <= ln < L:\n",
        "                line_labels[ln] = 1.0\n",
        "\n",
        "        file_label = torch.tensor(rec[\"file_label\"], dtype=torch.long)\n",
        "        mask_lines = torch.ones(L, dtype=torch.bool)\n",
        "\n",
        "        sample = LineGraphSample(\n",
        "            x=ctx_out,\n",
        "            edge_index=edge_index,\n",
        "            edge_type=edge_type,\n",
        "            line_labels=line_labels,\n",
        "            file_label=file_label,\n",
        "            mask_lines=mask_lines\n",
        "        )\n",
        "\n",
        "        if self.cache:\n",
        "            self._cache[idx] = sample\n",
        "\n",
        "        return sample\n"
      ],
      "metadata": {
        "id": "QCYY_PGBFm-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data and create DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate(samples):\n",
        "    return samples  # one file per batch\n",
        "\n",
        "train_ds = DefectDataset(train_records, cache=True)\n",
        "val_ds   = DefectDataset(val_records,   cache=False)\n",
        "test_ds  = DefectDataset(test_records,  cache=False)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_ds))\n",
        "print(\"Val:  \", len(val_ds))\n",
        "print(\"Test: \", len(test_ds))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLJutnho0IY",
        "outputId": "fccf5a71-b2f8-400a-b99f-e799d8e43f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 499\n",
            "Val:   28\n",
            "Test:  27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAT fusion and dual-head model\n",
        "\n",
        "Edge-type embeddings: Inject coarse edge-type info into GAT via an augmentation trick.\n",
        "\n",
        "Residuals and normalization: Keep features stable and avoid over-smoothing.\n",
        "\n",
        "Heads:\n",
        "\n",
        "Line-level sigmoid for per-line probabilities\n",
        "File-level attention pooling + MLP for buggy vs clean"
      ],
      "metadata": {
        "id": "U_A40nvAgHQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATConv, GlobalAttention\n",
        "\n",
        "class LineDefectModel(nn.Module):\n",
        "    def __init__(self, in_dim=512, hidden=256, heads1=8, heads2=4, num_edge_types=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.edge_emb = nn.Embedding(num_edge_types, 16)\n",
        "        self.gat1 = GATConv(in_dim + 16, hidden, heads=heads1, dropout=dropout, concat=True)\n",
        "        self.gat2 = GATConv(hidden*heads1 + 16, hidden, heads=heads2, dropout=dropout, concat=True)\n",
        "        out_dim = hidden*heads2\n",
        "        self.norm = nn.LayerNorm(out_dim)\n",
        "        self.line_head = nn.Linear(out_dim, 1)\n",
        "        self.gate_nn = nn.Sequential(nn.Linear(out_dim, 64), nn.ReLU(), nn.Linear(64, 1))\n",
        "        self.global_att = GlobalAttention(gate_nn=self.gate_nn)\n",
        "        self.file_head = nn.Sequential(nn.Linear(out_dim, 256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256, 2))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_type, mask_lines=None):\n",
        "        if edge_index.numel() == 0:\n",
        "            h = self.norm(x)\n",
        "        else:\n",
        "            e = self.edge_emb(edge_type)\n",
        "            src, dst = edge_index\n",
        "            # Aggregate edge-type embeddings to source nodes (approximate edge feature injection)\n",
        "            aug1 = torch.zeros((x.size(0), e.size(1)), device=x.device)\n",
        "            aug1.index_add_(0, src, e)\n",
        "            x1 = torch.cat([x, aug1], dim=1)\n",
        "            h1 = self.gat1(x1, edge_index)\n",
        "            h1 = F.elu(h1)\n",
        "            # Second layer with updated augmentation\n",
        "            aug2 = torch.zeros((h1.size(0), e.size(1)), device=h1.device)\n",
        "            aug2.index_add_(0, src, e)\n",
        "            x2 = torch.cat([h1, aug2], dim=1)\n",
        "            h2 = self.gat2(x2, edge_index)\n",
        "            h = self.norm(h2)\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        line_logits = self.line_head(h).squeeze(-1)  # [L]\n",
        "        if mask_lines is None:\n",
        "            mask_lines = torch.ones(h.size(0), dtype=torch.bool, device=h.device)\n",
        "        file_repr = self.global_att(h[mask_lines])   # [D]\n",
        "        file_logits = self.file_head(file_repr)      # [2]\n",
        "        return line_logits, file_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWAUhE-Vgodq",
        "outputId": "7aa41986-74de-41a5-cbba-3855e5c8aa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses, optimizer, and training loop\n",
        "\n",
        "Focal loss: For line-level imbalance.\n",
        "\n",
        "Multi-task loss: Emphasize line-level learning while keeping file-level useful.\n",
        "\n",
        "Gradient clipping: Stability."
      ],
      "metadata": {
        "id": "i1WR8514g7FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(prob, target, alpha=0.25, gamma=2.0, eps=1e-6):\n",
        "    prob = torch.clamp(prob, eps, 1.0 - eps)\n",
        "    ce_pos = -torch.log(prob)\n",
        "    ce_neg = -torch.log(1.0 - prob)\n",
        "    loss = alpha * (1 - prob)**gamma * target * ce_pos + (1 - alpha) * (prob**gamma) * (1 - target) * ce_neg\n",
        "    return loss.mean()\n",
        "\n",
        "lambda_line, lambda_file = 2.0, 1.0\n",
        "model = LineDefectModel().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "def train_epoch(loader):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for batch in loader:\n",
        "        sample = batch[0]  # single sample per batch\n",
        "        x = sample.x.to(device)\n",
        "        edge_index = sample.edge_index.to(device)\n",
        "        edge_type = sample.edge_type.to(device)\n",
        "        line_labels = sample.line_labels.to(device)\n",
        "        file_label = sample.file_label.to(device)\n",
        "        mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "        line_prob = torch.sigmoid(line_logits)\n",
        "        line_loss = focal_loss(line_prob, line_labels)\n",
        "\n",
        "        # Convert file_label to one-hot encoding for F.cross_entropy\n",
        "        num_classes = 2 # Assuming 2 classes: buggy and non-buggy\n",
        "        file_label_one_hot = F.one_hot(file_label, num_classes=num_classes).float()\n",
        "        file_loss = F.cross_entropy(file_logits.unsqueeze(0), file_label_one_hot.unsqueeze(0))\n",
        "        file_loss = F.cross_entropy(file_logits, file_label.unsqueeze(0))\n",
        "\n",
        "\n",
        "        loss = lambda_line * line_loss + lambda_file * file_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total / max(1, len(loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz3hAuEnhDkh",
        "outputId": "0f43fbe7-2734-4cc9-fd54-c7a0ed0efd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "File-level: Accuracy, F1, ROC-AUC, PR-AUC\n",
        "\n",
        "Line-level: PR-AUC (global), plus Top‑k and MRR for localization"
      ],
      "metadata": {
        "id": "16x72EOnhKh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    file_probs, file_labels = [], []\n",
        "    line_probs, line_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sample = batch[0]\n",
        "            x = sample.x.to(device)\n",
        "            edge_index = sample.edge_index.to(device)\n",
        "            edge_type = sample.edge_type.to(device)\n",
        "            mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "            line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "            fp = torch.softmax(file_logits, dim=-1)[1].item()\n",
        "            file_probs.append(fp)\n",
        "            file_labels.append(sample.file_label.item())\n",
        "\n",
        "            lp = torch.sigmoid(line_logits).cpu().numpy().tolist()\n",
        "            ll = sample.line_labels.cpu().numpy().tolist()\n",
        "            line_probs.extend(lp)\n",
        "            line_labels.extend(ll)\n",
        "\n",
        "    # File-level\n",
        "    file_probs_np = np.array(file_probs)\n",
        "    file_labels_np = np.array(file_labels)\n",
        "    file_preds_bin = (file_probs_np >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(file_labels_np, file_preds_bin)\n",
        "    f1 = f1_score(file_labels_np, file_preds_bin)\n",
        "    try:\n",
        "        roc = roc_auc_score(file_labels_np, file_probs_np)\n",
        "    except Exception:\n",
        "        roc = float('nan')\n",
        "    pr = average_precision_score(file_labels_np, file_probs_np)\n",
        "\n",
        "    # Line-level (global PR-AUC across all lines)\n",
        "    line_probs_np = np.array(line_probs)\n",
        "    line_labels_np = np.array(line_labels)\n",
        "    l_pr = average_precision_score(line_labels_np, line_probs_np)\n",
        "\n",
        "    return {\n",
        "        \"file\": {\"acc\": acc, \"f1\": f1, \"roc\": roc, \"pr\": pr},\n",
        "        \"line\": {\"pr\": l_pr}\n",
        "    }\n",
        "\n",
        "def topk_mrr(loader, k=5):\n",
        "    model.eval()\n",
        "    hits, rr_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sample = batch[0]\n",
        "            x = sample.x.to(device)\n",
        "            edge_index = sample.edge_index.to(device)\n",
        "            edge_type = sample.edge_type.to(device)\n",
        "            mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "            line_logits, _ = model(x, edge_index, edge_type, mask_lines)\n",
        "            probs = torch.sigmoid(line_logits).cpu().numpy()\n",
        "            buggy_idx = np.where(sample.line_labels.cpu().numpy() > 0.5)[0]\n",
        "            if len(buggy_idx) == 0:\n",
        "                continue\n",
        "            order = np.argsort(-probs)\n",
        "            topk = order[:k]\n",
        "            hit = int(any(b in topk for b in buggy_idx))\n",
        "            hits.append(hit)\n",
        "            ranks = [np.where(order == b)[0][0] + 1 for b in buggy_idx]\n",
        "            rr = 1.0 / min(ranks)\n",
        "            rr_list.append(rr)\n",
        "    hit_rate = np.mean(hits) if hits else 0.0\n",
        "    mrr = np.mean(rr_list) if rr_list else 0.0\n",
        "    return hit_rate, mrr"
      ],
      "metadata": {
        "id": "NMQsiuRihJiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and Validate\n",
        "\n",
        "For real datasets, increase epochs (e.g., 20–40), and consider caching embeddings to disk for speed."
      ],
      "metadata": {
        "id": "_4spKxinhaTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6\n",
        "\n",
        "for ep in range(1, epochs + 1):\n",
        "    tr_loss = train_epoch(train_loader)\n",
        "    val_metrics = evaluate(val_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {ep:02d} | \"\n",
        "        f\"TrainLoss {tr_loss:.4f} | \"\n",
        "        f\"Val File(\"\n",
        "        f\"acc {val_metrics['file']['acc']:.3f}, \"\n",
        "        f\"f1 {val_metrics['file']['f1']:.3f}, \"\n",
        "        f\"roc {val_metrics['file']['roc']:.3f}, \"\n",
        "        f\"pr {val_metrics['file']['pr']:.3f}\"\n",
        "        f\") | \"\n",
        "        f\"Line (pr {val_metrics['line']['pr']:.3f})\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "XGK1C3kohd4m",
        "outputId": "40f96e39-9e18-4d90-e194-dad299afe335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected scalar type Long but found Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2853596986.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4263548790.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# Assuming 2 classes: buggy and non-buggy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mfile_label_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfile_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_label_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_line\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mline_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_file\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfile_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3459\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tree_sitter import Parser\n",
        "from tree_sitter_languages import get_language\n",
        "\n",
        "parser = Parser()\n",
        "PY_LANGUAGE = get_language(\"python\")\n",
        "parser.set_language(PY_LANGUAGE)\n",
        "\n",
        "print(\"Tree-sitter Python loaded ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3rl_SrebhX3",
        "outputId": "168942e3-a715-4e74-cd02-50024f197017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree-sitter Python loaded ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AST parsing (line spans)\n",
        "def parse_ast_nodes(code: str):\n",
        "    tree = parser.parse(bytes(code, \"utf8\"))\n",
        "    root = tree.root_node\n",
        "    spans = []\n",
        "\n",
        "    def visit(node):\n",
        "        spans.append((node.type, node.start_point[0], node.end_point[0]))\n",
        "        for child in node.children:\n",
        "            visit(child)\n",
        "\n",
        "    visit(root)\n",
        "    return spans\n"
      ],
      "metadata": {
        "id": "r7WoJTAIbpM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CPG-lite builder (CFG + AST + PDG)\n",
        "def build_cpg(lines):\n",
        "    num_lines = len(lines)\n",
        "    edge_index = []\n",
        "    edge_type = []\n",
        "\n",
        "    # CFG-lite\n",
        "    for i in range(num_lines - 1):\n",
        "        edge_index += [[i, i+1], [i+1, i]]\n",
        "        edge_type += [0, 0]\n",
        "\n",
        "    # AST-lite\n",
        "    spans = parse_ast_nodes(\"\\n\".join(lines))\n",
        "    for _, s, e in spans:\n",
        "        for i in range(max(0, s), min(e, num_lines - 1)):\n",
        "            edge_index += [[i, i+1], [i+1, i]]\n",
        "            edge_type += [1, 1]\n",
        "\n",
        "    # PDG-lite\n",
        "    def extract_ids(line):\n",
        "        toks = ''.join(c if c.isalnum() or c=='_' else ' ' for c in line).split()\n",
        "        stop = {\n",
        "            \"def\",\"class\",\"return\",\"if\",\"else\",\"for\",\"while\",\"import\",\"from\",\n",
        "            \"True\",\"False\",\"None\",\"and\",\"or\",\"not\"\n",
        "        }\n",
        "        return [t for t in toks if len(t) > 1 and t not in stop]\n",
        "\n",
        "    id_map = {}\n",
        "    for i, line in enumerate(lines):\n",
        "        for t in extract_ids(line):\n",
        "            id_map.setdefault(t, []).append(i)\n",
        "\n",
        "    for idxs in id_map.values():\n",
        "        idxs = list(set(idxs))\n",
        "        for a in idxs:\n",
        "            for b in idxs:\n",
        "                if a != b and abs(a-b) <= 15:\n",
        "                    edge_index.append([a,b])\n",
        "                    edge_type.append(2)\n",
        "\n",
        "    return (\n",
        "        torch.tensor(edge_index).t().contiguous(),\n",
        "        torch.tensor(edge_type)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ReXqmKjQbxh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CodeBERT line embeddings\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\").to(device)\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_lines(lines):\n",
        "    inputs = tokenizer(\n",
        "        lines, padding=True, truncation=True,\n",
        "        max_length=128, return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "    out = model(**inputs)\n",
        "    return out.last_hidden_state[:,0,:].cpu()\n"
      ],
      "metadata": {
        "id": "0WbAD8MFb6vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/black_only/train_black.csv\")\n",
        "\n",
        "# Convert DataFrame → list of dicts\n",
        "train_data = train_df.to_dict(orient=\"records\")\n",
        "\n",
        "# Fix 'Induce bug' column and add 'file_label'\n",
        "for r in train_data:\n",
        "    # Handle 'Induce bug' column: if NaN or malformed string, default to empty list\n",
        "    if isinstance(r[\"Induce bug\"], str):\n",
        "        cleaned_str_content = r[\"Induce bug\"].strip('[] ')\n",
        "        if cleaned_str_content:\n",
        "            parts = cleaned_str_content.split()\n",
        "            formatted_list_str = f\"[{', '.join(parts)}]\"\n",
        "        else:\n",
        "            formatted_list_str = \"[]\"\n",
        "        try:\n",
        "            r[\"Induce bug\"] = ast.literal_eval(formatted_list_str)\n",
        "        except (ValueError, SyntaxError):\n",
        "            r[\"Induce bug\"] = [] # Fallback to empty list if parsing fails\n",
        "    elif pd.isna(r[\"Induce bug\"]):\n",
        "        r[\"Induce bug\"] = []\n",
        "\n",
        "    # Add 'file_label' if missing, defaulting to 0\n",
        "    if \"file_label\" not in r:\n",
        "        r[\"file_label\"] = 0\n"
      ],
      "metadata": {
        "id": "HUPRYMPS4ocP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== End-to-end test using dataset record (FIXED) =====\n",
        "\n",
        "rec = train_data[0]\n",
        "\n",
        "# Fix escaped newlines\n",
        "code = rec[\"content\"].encode(\"utf-8\").decode(\"unicode_escape\")\n",
        "lines = code.split(\"\\n\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    embs = encode_lines(lines)\n",
        "\n",
        "edges, etypes = build_cpg(lines)\n",
        "etypes = etypes.long()\n",
        "\n",
        "print(\"Repository:\", rec[\"repo\"])\n",
        "print(\"File path:\", rec[\"filepath\"])\n",
        "print(\"Commit:\", rec[\"commit\"])\n",
        "print(\"Total lines:\", len(lines))\n",
        "print(\"Buggy lines:\", rec[\"Induce bug\"])\n",
        "\n",
        "print(\"\\nLine embeddings shape:\", embs.shape)\n",
        "print(\"Edges shape:\", edges.shape)\n",
        "print(\"Edge types distribution:\", torch.bincount(etypes))\n",
        "\n",
        "print(\"\\n✅ FULL PIPELINE WORKING ON REAL DATA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpTu9e8A53TA",
        "outputId": "288e5e49-4608-47a0-876b-e44d53e7e24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository: black\n",
            "File path: src\\black\\linegen.py\n",
            "Commit: 00e7e12a3a412ea386806d5d4eeaed345e912940\n",
            "Total lines: 791\n",
            "Buggy lines: []\n",
            "\n",
            "Line embeddings shape: torch.Size([791, 768])\n",
            "Edges shape: torch.Size([2, 17474])\n",
            "Edge types distribution: tensor([1580, 9992, 5902])\n",
            "\n",
            "✅ FULL PIPELINE WORKING ON REAL DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset class: building samples end-to-end\n",
        "#We embed lines, contextualize, build graphs, and prepare labels per file\n",
        "\n",
        "class LineGraphSample:\n",
        "    def __init__(self, x, edge_index, edge_type, line_labels, file_label, mask_lines):\n",
        "        self.x = x                # [L, Feat]\n",
        "        self.edge_index = edge_index  # [2, E]\n",
        "        self.edge_type = edge_type    # [E]\n",
        "        self.line_labels = line_labels  # [L]\n",
        "        self.file_label = file_label    # scalar\n",
        "        self.mask_lines = mask_lines    # boolean mask for pooling\n",
        "\n",
        "class DefectDataset(Dataset):\n",
        "    def __init__(self, records, cache=False):\n",
        "        self.records = records\n",
        "        self.cache = cache\n",
        "        self._cache = [None]*len(records)\n",
        "\n",
        "    def __len__(self): return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.cache and self._cache[idx] is not None:\n",
        "            return self._cache[idx]\n",
        "        rec = self.records[idx]\n",
        "        lines = rec[\"content\"].split(\"\\n\")\n",
        "        # Step 1: CodeBERT line embeddings\n",
        "        with torch.no_grad():\n",
        "            line_embs = embed_lines_with_codebert(lines)  # [L, 768]\n",
        "        # Step 2: Contextualization\n",
        "        ctx_inp = line_embs.unsqueeze(0)  # [1, L, 768]\n",
        "        ctx_out = context_encoder(ctx_inp).squeeze(0)  # [L, 512]\n",
        "        # Step 3: Graph construction (CPG-lite)\n",
        "        edge_index, edge_type = build_cpg(lines)\n",
        "        # Step 4: labels\n",
        "        L = len(lines)\n",
        "        line_labels = torch.zeros(L, dtype=torch.float32)\n",
        "        for ln in rec[\"induce_bug\"]:\n",
        "            if 0 <= ln < L:\n",
        "                line_labels[ln] = 1.0\n",
        "        file_label = torch.tensor(rec[\"file_label\"], dtype=torch.long)\n",
        "        mask_lines = torch.ones(L, dtype=torch.bool)  # all lines included\n",
        "        sample = LineGraphSample(ctx_out, edge_index, edge_type, line_labels, file_label, mask_lines)\n",
        "        if self.cache:\n",
        "            self._cache[idx] = sample\n",
        "        return sample\n",
        "\n",
        "# Split data\n",
        "random.shuffle(data)\n",
        "train_split = int(0.7 * len(data))\n",
        "val_split = int(0.85 * len(data))\n",
        "train_ds = DefectDataset(data[:train_split], cache=True)\n",
        "val_ds = DefectDataset(data[train_split:val_split], cache=False)\n",
        "test_ds = DefectDataset(data[val_split:], cache=False)\n",
        "\n",
        "def collate(samples):\n",
        "    # We will process each file separately (no graph batching to keep things simple in Colab)\n",
        "    return samples\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, collate_fn=collate)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, collate_fn=collate)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=collate)\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_hPnI4c0ZoDB",
        "outputId": "9e49bb44-6fb3-4d72-b05b-ed6bec459b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-977795291.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mtrain_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mval_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model: GAT fusion + dual heads (line and file)\n",
        "#We use PyTorch Geometric’s GATConv. Edge types are handled via learned type embeddings concatenated to messages.\n",
        "\n",
        "from torch_geometric.nn import GATConv, GlobalAttention\n",
        "\n",
        "class LineDefectModel(nn.Module):\n",
        "    def __init__(self, in_dim=512, hidden=256, heads1=8, heads2=4, num_edge_types=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.edge_emb = nn.Embedding(num_edge_types, 16)\n",
        "        self.gat1 = GATConv(in_dim + 16, hidden, heads=heads1, dropout=dropout, concat=True)\n",
        "        self.gat2 = GATConv(hidden*heads1 + 16, hidden, heads=heads2, dropout=dropout, concat=True)\n",
        "        out_dim = hidden*heads2\n",
        "        self.norm = nn.LayerNorm(out_dim)\n",
        "        self.line_head = nn.Linear(out_dim, 1)\n",
        "        self.gate_nn = nn.Sequential(nn.Linear(out_dim, 64), nn.ReLU(), nn.Linear(64, 1))\n",
        "        self.global_att = GlobalAttention(gate_nn=self.gate_nn)\n",
        "        self.file_head = nn.Sequential(nn.Linear(out_dim, 256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256, 2))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_type, mask_lines=None):\n",
        "        if edge_index.numel() == 0:\n",
        "            # No edges: fall back to MLP\n",
        "            h = self.norm(x)\n",
        "        else:\n",
        "            e = self.edge_emb(edge_type)\n",
        "            # Expand edge-type features to source nodes (message trick)\n",
        "            # GATConv doesn't natively take edge features; we concatenate edge-type emb to node features per edge via indexing\n",
        "            # We implement by augmenting node features replicated along edges:\n",
        "            # For implementation simplicity in single-file batches, we attach edge-type emb to the source node features at aggregation time:\n",
        "            # Create augmented node features by summing edge-type embeddings for incoming edges (approximation).\n",
        "            aug = torch.zeros((x.size(0), e.size(1)), device=x.device)\n",
        "            src, dst = edge_index\n",
        "            aug.index_add_(0, src, e)  # aggregate edge-type emb to source\n",
        "            x1 = torch.cat([x, aug], dim=1)\n",
        "            h1 = self.gat1(x1, edge_index)\n",
        "            h1 = F.elu(h1)\n",
        "            # second layer\n",
        "            aug2 = torch.zeros((h1.size(0), e.size(1)), device=h1.device)\n",
        "            aug2.index_add_(0, src, e)\n",
        "            x2 = torch.cat([h1, aug2], dim=1)\n",
        "            h2 = self.gat2(x2, edge_index)\n",
        "            h = self.norm(h2)\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        line_logits = self.line_head(h).squeeze(-1)  # [L]\n",
        "        if mask_lines is None:\n",
        "            mask_lines = torch.ones(h.size(0), dtype=torch.bool, device=h.device)\n",
        "        file_repr = self.global_att(h[mask_lines])   # [D]\n",
        "        file_logits = self.file_head(file_repr)      # [2]\n",
        "        return line_logits, file_logits"
      ],
      "metadata": {
        "id": "gtM5J8o-Z8g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Losses: focal loss for line-level, CE for file-leve\n",
        "def focal_loss(prob, target, alpha=0.25, gamma=2.0, eps=1e-6):\n",
        "    # prob: [L], target: [L] in {0,1}\n",
        "    prob = torch.clamp(prob, eps, 1.0 - eps)\n",
        "    ce_pos = -torch.log(prob)\n",
        "    ce_neg = -torch.log(1.0 - prob)\n",
        "    loss = alpha * (1 - prob)**gamma * target * ce_pos + (1 - alpha) * (prob**gamma) * (1 - target) * ce_neg\n",
        "    return loss.mean()\n",
        "\n",
        "lambda_line, lambda_file = 2.0, 1.0\n",
        "model = LineDefectModel().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "HrFl2wuoaGSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training loop\n",
        "def train_epoch(loader):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for batch in loader:\n",
        "        # single-sample batches for simplicity\n",
        "        sample = batch[0]\n",
        "        x = sample.x.to(device)\n",
        "        edge_index = sample.edge_index.to(device)\n",
        "        edge_type = sample.edge_type.to(device)\n",
        "        line_labels = sample.line_labels.to(device)\n",
        "        file_label = sample.file_label.to(device)\n",
        "        mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "        line_prob = torch.sigmoid(line_logits)\n",
        "        line_loss = focal_loss(line_prob, line_labels)\n",
        "        file_loss = F.cross_entropy(file_logits.unsqueeze(0), file_label.unsqueeze(0))\n",
        "        loss = lambda_line * line_loss + lambda_file * file_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total / len(loader)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    file_probs, file_labels = [], []\n",
        "    line_probs, line_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sample = batch[0]\n",
        "            x = sample.x.to(device)\n",
        "            edge_index = sample.edge_index.to(device)\n",
        "            edge_type = sample.edge_type.to(device)\n",
        "            mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "            line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "            fp = torch.softmax(file_logits, dim=-1)[1].item()\n",
        "            file_probs.append(fp)\n",
        "            file_labels.append(sample.file_label.item())\n",
        "\n",
        "            lp = torch.sigmoid(line_logits).detach().cpu().numpy().tolist()\n",
        "            ll = sample.line_labels.detach().cpu().numpy().tolist()\n",
        "            line_probs.extend(lp)\n",
        "            line_labels.extend(ll)\n",
        "\n",
        "    # File-level metrics\n",
        "    file_probs_np = np.array(file_probs)\n",
        "    file_labels_np = np.array(file_labels)\n",
        "    file_preds_bin = (file_probs_np >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(file_labels_np, file_preds_bin)\n",
        "    f1 = f1_score(file_labels_np, file_preds_bin)\n",
        "    try:\n",
        "        roc = roc_auc_score(file_labels_np, file_probs_np)\n",
        "    except:\n",
        "        roc = float('nan')\n",
        "    pr = average_precision_score(file_labels_np, file_probs_np)\n",
        "\n",
        "    # Line-level metrics (PR-AUC)\n",
        "    line_probs_np = np.array(line_probs)\n",
        "    line_labels_np = np.array(line_labels)\n",
        "    l_pr = average_precision_score(line_labels_np, line_probs_np)\n",
        "\n",
        "    return {\n",
        "        \"file\": {\"acc\": acc, \"f1\": f1, \"roc\": roc, \"pr\": pr},\n",
        "        \"line\": {\"pr\": l_pr}\n",
        "    }\n",
        "\n",
        "# Train\n",
        "epochs = 6\n",
        "for ep in range(1, epochs+1):\n",
        "    tr_loss = train_epoch(train_loader)\n",
        "    val_metrics = evaluate(val_loader)\n",
        "    print(f\"Epoch {ep:02d} | TrainLoss {tr_loss:.4f} | \"\n",
        "          f\"Val File(acc {val_metrics['file']['acc']:.3f}, f1 {val_metrics['file']['f1']:.3f}, \"\n",
        "          f\"roc {val_metrics['file']['roc']:.3f}, pr {val_metrics['file']['pr']:.3f}) | \"\n",
        "          f\"Line (pr {val_metrics['line']['pr']:.3f})\")"
      ],
      "metadata": {
        "id": "ywY6mCHFaOWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-k hit and MRR for line-level localization\n",
        "\n",
        "def topk_mrr(loader, k=5):\n",
        "    model.eval()\n",
        "    hits, rr_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sample = batch[0]\n",
        "            x = sample.x.to(device)\n",
        "            edge_index = sample.edge_index.to(device)\n",
        "            edge_type = sample.edge_type.to(device)\n",
        "            mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "            line_logits, _ = model(x, edge_index, edge_type, mask_lines)\n",
        "            probs = torch.sigmoid(line_logits).detach().cpu().numpy()\n",
        "            buggy_idx = np.where(sample.line_labels.cpu().numpy() > 0.5)[0]\n",
        "            if len(buggy_idx) == 0:\n",
        "                continue\n",
        "            # Rank lines by prob\n",
        "            order = np.argsort(-probs)\n",
        "            topk = order[:k]\n",
        "            hit = int(any(b in topk for b in buggy_idx))\n",
        "            hits.append(hit)\n",
        "            # Reciprocal rank\n",
        "            ranks = [np.where(order == b)[0][0] + 1 for b in buggy_idx]\n",
        "            rr = 1.0 / min(ranks)\n",
        "            rr_list.append(rr)\n",
        "    hit_rate = np.mean(hits) if hits else 0.0\n",
        "    mrr = np.mean(rr_list) if rr_list else 0.0\n",
        "    return hit_rate, mrr\n",
        "\n",
        "test_metrics = evaluate(test_loader)\n",
        "hit5, mrr = topk_mrr(test_loader, k=5)\n",
        "\n",
        "print(f\"Test File: Acc={test_metrics['file']['acc']:.3f} F1={test_metrics['file']['f1']:.3f} \"\n",
        "      f\"ROC={test_metrics['file']['roc']:.3f} PR={test_metrics['file']['pr']:.3f}\")\n",
        "print(f\"Test Line: PR-AUC={test_metrics['line']['pr']:.3f} Top-5 Hit={hit5:.3f} MRR={mrr:.3f}\")"
      ],
      "metadata": {
        "id": "nQ_4Dj6kat0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference and visualization: line scores per file\n",
        "\n",
        "\n",
        "def inspect_sample(sample_idx=0, loader=test_loader):\n",
        "    sample = list(loader)[sample_idx][0]\n",
        "    x = sample.x.to(device)\n",
        "    edge_index = sample.edge_index.to(device)\n",
        "    edge_type = sample.edge_type.to(device)\n",
        "    mask_lines = sample.mask_lines.to(device)\n",
        "    lines = data[val_split + sample_idx][\"content\"].split(\"\\n\")\n",
        "    with torch.no_grad():\n",
        "        line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "        probs = torch.sigmoid(line_logits).cpu().numpy()\n",
        "        file_prob = torch.softmax(file_logits, dim=-1)[1].item()\n",
        "    ranked = np.argsort(-probs)\n",
        "    print(f\"File buggy prob: {file_prob:.3f} | True label: {sample.file_label.item()}\")\n",
        "    print(\"Top-10 lines:\")\n",
        "    for r in ranked[:10]:\n",
        "        flag = (\"<BUG>\" if sample.line_labels[r].item() > 0.5 else \"\")\n",
        "        print(f\"{r:4d}  prob={probs[r]:.3f}  {flag}  | {lines[r][:100]}\")\n",
        "\n",
        "inspect_sample(0)"
      ],
      "metadata": {
        "id": "jP3nrBJua3bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)\n",
        "sum(d[\"file_label\"] for d in data if d[\"file_label\"] == 1)\n",
        "set(d[\"repo\"] for d in data)\n"
      ],
      "metadata": {
        "id": "WjoMTa7H_kZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facc6b7f"
      },
      "source": [
        "# Task\n",
        "Extract all unique file paths and count all unique commit hashes from the `data` list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c11acc9"
      },
      "source": [
        "unique_filepaths = set()\n",
        "for item in data:\n",
        "    if 'filepath' in item:\n",
        "        unique_filepaths.add(item['filepath'])\n",
        "\n",
        "unique_filepaths_list = list(unique_filepaths)\n",
        "\n",
        "print(f\"Number of unique file paths: {len(unique_filepaths_list)}\")\n",
        "print(\"First 5 unique file paths:\")\n",
        "for i, path in enumerate(unique_filepaths_list[:5]):\n",
        "    print(f\"- {path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9a922d"
      },
      "source": [
        "# Task\n",
        "Modify the data loading cell `MfqQ48vx-9Qm` to add placeholder `induce_bug` (an empty list) and `file_label` (0) to each record in the `data` list loaded from \"black_repo - black_repo.csv\", then re-run the modified data loading cell and the subsequent cells (`_hPnI4c0ZoDB`, `ywY6mCHFaOWm`) to resolve the `KeyError` and enable the training process to proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87b25c8"
      },
      "source": [
        "## Add Missing Labels\n",
        "\n",
        "### Subtask:\n",
        "Modify the data loading cell (`MfqQ48vx-9Qm`) to add placeholder `induce_bug` (an empty list) and `file_label` (0) to each record in the `data` list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ec22f9"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `data` list to include placeholder `induce_bug` and `file_label` for each record. I will update the code in cell `MfqQ48vx-9Qm` to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e838093"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('black_repo - black_repo.csv')\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Add placeholder for 'induce_bug' and 'file_label' for each record\n",
        "for record in data:\n",
        "    record['induce_bug'] = []\n",
        "    record['file_label'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be3b84a1"
      },
      "source": [
        "**Reasoning**:\n",
        "The data modification has been successfully applied to the `data` list in the previous step. To ensure the training pipeline uses this updated data structure and resolve the `KeyError`, the `DefectDataset` class and the data loaders need to be re-initialized by re-running cell `_hPnI4c0ZoDB`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69280f23"
      },
      "source": [
        "#Dataset class: building samples end-to-end\n",
        "#We embed lines, contextualize, build graphs, and prepare labels per file\n",
        "\n",
        "class LineGraphSample:\n",
        "    def __init__(self, x, edge_index, edge_type, line_labels, file_label, mask_lines):\n",
        "        self.x = x                # [L, Feat]\n",
        "        self.edge_index = edge_index  # [2, E]\n",
        "        self.edge_type = edge_type    # [E]\n",
        "        self.line_labels = line_labels  # [L]\n",
        "        self.file_label = file_label    # scalar\n",
        "        self.mask_lines = mask_lines    # boolean mask for pooling\n",
        "\n",
        "class DefectDataset(Dataset):\n",
        "    def __init__(self, records, cache=False):\n",
        "        self.records = records\n",
        "        self.cache = cache\n",
        "        self._cache = [None]*len(records)\n",
        "\n",
        "    def __len__(self): return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.cache and self._cache[idx] is not None:\n",
        "            return self._cache[idx]\n",
        "        rec = self.records[idx]\n",
        "        lines = rec[\"content\"].split(\"\\n\")\n",
        "        # Step 1: CodeBERT line embeddings\n",
        "        with torch.no_grad():\n",
        "            line_embs = embed_lines_with_codebert(lines)  # [L, 768]\n",
        "        # Step 2: Contextualization\n",
        "        ctx_inp = line_embs.unsqueeze(0)  # [1, L, 768]\n",
        "        ctx_out = context_encoder(ctx_inp).squeeze(0)  # [L, 512]\n",
        "        # Step 3: Graph construction (CPG-lite)\n",
        "        edge_index, edge_type = build_cpg(lines)\n",
        "        # Step 4: labels\n",
        "        L = len(lines)\n",
        "        line_labels = torch.zeros(L, dtype=torch.float32)\n",
        "        for ln in rec[\"induce_bug\"]:\n",
        "            if 0 <= ln < L:\n",
        "                line_labels[ln] = 1.0\n",
        "        file_label = torch.tensor(rec[\"file_label\"], dtype=torch.long)\n",
        "        mask_lines = torch.ones(L, dtype=torch.bool)  # all lines included\n",
        "        sample = LineGraphSample(ctx_out, edge_index, edge_type, line_labels, file_label, mask_lines)\n",
        "        if self.cache:\n",
        "            self._cache[idx] = sample\n",
        "        return sample\n",
        "\n",
        "# Split data\n",
        "random.shuffle(data)\n",
        "train_split = int(0.7 * len(data))\n",
        "val_split = int(0.85 * len(data))\n",
        "train_ds = DefectDataset(data[:train_split], cache=True)\n",
        "val_ds = DefectDataset(data[train_split:val_split], cache=False)\n",
        "test_ds = DefectDataset(data[val_split:], cache=False)\n",
        "\n",
        "def collate(samples):\n",
        "    # We will process each file separately (no graph batching to keep things simple in Colab)\n",
        "    return samples\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, collate_fn=collate)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, collate_fn=collate)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=collate)\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6a3cc80"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully re-initialized the dataset with the updated `data` list. Now, re-running the training loop (cell `ywY6mCHFaOWm`) will allow the model to train without encountering the `KeyError` related to `induce_bug`, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69f6fc60"
      },
      "source": [
        "#Training loop\n",
        "def train_epoch(loader):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for batch in loader:\n",
        "        # single-sample batches for simplicity\n",
        "        sample = batch[0]\n",
        "        x = sample.x.to(device)\n",
        "        edge_index = sample.edge_index.to(device)\n",
        "        edge_type = sample.edge_type.to(device)\n",
        "        line_labels = sample.line_labels.to(device)\n",
        "        file_label = sample.file_label.to(device)\n",
        "        mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "        line_prob = torch.sigmoid(line_logits)\n",
        "        line_loss = focal_loss(line_prob, line_labels)\n",
        "        file_loss = F.cross_entropy(file_logits.unsqueeze(0), file_label.unsqueeze(0))\n",
        "        loss = lambda_line * line_loss + lambda_file * file_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total / len(loader)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    file_probs, file_labels = [], []\n",
        "    line_probs, line_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sample = batch[0]\n",
        "            x = sample.x.to(device)\n",
        "            edge_index = sample.edge_index.to(device)\n",
        "            edge_type = sample.edge_type.to(device)\n",
        "            mask_lines = sample.mask_lines.to(device)\n",
        "\n",
        "            line_logits, file_logits = model(x, edge_index, edge_type, mask_lines)\n",
        "            fp = torch.softmax(file_logits, dim=-1)[1].item()\n",
        "            file_probs.append(fp)\n",
        "            file_labels.append(sample.file_label.item())\n",
        "\n",
        "            lp = torch.sigmoid(line_logits).detach().cpu().numpy().tolist()\n",
        "            ll = sample.line_labels.detach().cpu().numpy().tolist()\n",
        "            line_probs.extend(lp)\n",
        "            line_labels.extend(ll)\n",
        "\n",
        "    # File-level metrics\n",
        "    file_probs_np = np.array(file_probs)\n",
        "    file_labels_np = np.array(file_labels)\n",
        "    file_preds_bin = (file_probs_np >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(file_labels_np, file_preds_bin)\n",
        "    f1 = f1_score(file_labels_np, file_preds_bin)\n",
        "    try:\n",
        "        roc = roc_auc_score(file_labels_np, file_probs_np)\n",
        "    except:\n",
        "        roc = float('nan')\n",
        "    pr = average_precision_score(file_labels_np, file_probs_np)\n",
        "\n",
        "    # Line-level metrics (PR-AUC)\n",
        "    line_probs_np = np.array(line_probs)\n",
        "    line_labels_np = np.array(line_labels)\n",
        "    l_pr = average_precision_score(line_labels_np, line_probs_np)\n",
        "\n",
        "    return {\n",
        "        \"file\": {\"acc\": acc, \"f1\": f1, \"roc\": roc, \"pr\": pr},\n",
        "        \"line\": {\"pr\": l_pr}\n",
        "    }\n",
        "\n",
        "# Train\n",
        "epochs = 6\n",
        "for ep in range(1, epochs+1):\n",
        "    tr_loss = train_epoch(train_loader)\n",
        "    val_metrics = evaluate(val_loader)\n",
        "    print(f\"Epoch {ep:02d} | TrainLoss {tr_loss:.4f} | \"\n",
        "          f\"Val File(acc {val_metrics['file']['acc']:.3f}, f1 {val_metrics['file']['f1']:.3f}, \"\n",
        "          f\"roc {val_metrics['file']['roc']:.3f}, pr {val_metrics['file']['pr']:.3f}) | \"\n",
        "          f\"Line (pr {val_metrics['line']['pr']:.3f})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a9c52c6"
      },
      "source": [
        "## Modify End-to-End Test\n",
        "\n",
        "### Subtask:\n",
        "Update cell `TdEUil2QcDUC` to load code content dynamically from the first record of `train_data` instead of using a hardcoded string. This will allow the end-to-end test to use real data from `train_black.csv`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7b2613"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying cell `TdEUil2QcDUC` to dynamically load code content from `train_data` instead of using a hardcoded string. This involves accessing the `content` field of the first record in `train_data`, decoding it from bytes to a UTF-8 string, and then stripping leading/trailing whitespace. This will ensure the end-to-end test uses actual data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "c2d8351e",
        "outputId": "db9971f8-f508-425a-b738-45425ef8891b"
      },
      "source": [
        "code = train_data[0]['content'].decode('utf-8').strip()\n",
        "\n",
        "lines = code.split(\"\\n\")\n",
        "\n",
        "embs = encode_lines(lines)\n",
        "edges, etypes = build_cpg(lines)\n",
        "\n",
        "print(\"Line embeddings:\", embs.shape)\n",
        "print(\"Edges:\", edges.shape)\n",
        "print(\"Edge types:\", torch.bincount(etypes))\n",
        "print(\"✅ FULL PIPELINE WORKING\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'decode'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-528440063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db36b669"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to decode the 'content' field failed because it is already a string, not a byte string. The `decode('utf-8')` call should be removed. The subtask requires loading the content from `train_data` and stripping whitespace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "98522fec",
        "outputId": "0374a5ab-04d8-43d7-dd23-04c8bc39c746"
      },
      "source": [
        "code = train_data[0]['content'].strip()\n",
        "\n",
        "lines = code.split(\"\\n\")\n",
        "\n",
        "embs = encode_lines(lines)\n",
        "edges, etypes = build_cpg(lines)\n",
        "\n",
        "print(\"Line embeddings:\", embs.shape)\n",
        "print(\"Edges:\", edges.shape)\n",
        "print(\"Edge types:\", torch.bincount(etypes))\n",
        "print(\"✅ FULL PIPELINE WORKING\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line embeddings: torch.Size([1, 768])\n",
            "Edges: torch.Size([0])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "\"bincount_cpu\" not implemented for 'Float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2310667922.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Line embeddings:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Edges:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Edge types:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ FULL PIPELINE WORKING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: \"bincount_cpu\" not implemented for 'Float'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bede2940"
      },
      "source": [
        "**Reasoning**:\n",
        "The 'content' field in `train_data` is a string literal of a byte string (e.g., \"b'...' \"), not an actual byte string, which caused incorrect splitting into lines and led to empty `etypes` being a float tensor when `torch.bincount` was called. The fix involves using `ast.literal_eval` to correctly parse the content into a bytes object before decoding, and adding a check for empty `etypes` for robustness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4989d956",
        "outputId": "162d7e26-9d34-49df-f43d-ea1b5c33eb9d"
      },
      "source": [
        "import ast # New import needed to safely evaluate string literals\n",
        "\n",
        "# The 'content' field in train_data is a string representation of a byte string (e.g., \"b'...' \").\n",
        "# We need to use ast.literal_eval to convert this string literal into an actual bytes object,\n",
        "# and then decode it to a UTF-8 string.\n",
        "code_content_literal = train_data[0]['content']\n",
        "code = ast.literal_eval(code_content_literal).decode('utf-8').strip()\n",
        "\n",
        "lines = code.split(\"\\n\")\n",
        "\n",
        "embs = encode_lines(lines)\n",
        "edges, etypes = build_cpg(lines)\n",
        "\n",
        "print(\"Line embeddings:\", embs.shape)\n",
        "print(\"Edges:\", edges.shape)\n",
        "\n",
        "# Check if etypes is empty before calling bincount to avoid error on empty tensor\n",
        "if etypes.numel() > 0:\n",
        "    # etypes should be of type long if non-empty, but explicitly cast to ensure correct type\n",
        "    print(\"Edge types:\", torch.bincount(etypes.long()))\n",
        "else:\n",
        "    print(\"Edge types: No edges generated.\")\n",
        "print(\"✅ FULL PIPELINE WORKING\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line embeddings: torch.Size([985, 768])\n",
            "Edges: torch.Size([2, 21032])\n",
            "Edge types: tensor([ 1968, 12216,  6848])\n",
            "✅ FULL PIPELINE WORKING\n"
          ]
        }
      ]
    }
  ]
}